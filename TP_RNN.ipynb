{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOseb32OCmxLTlTNlaEsIUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VirgileH24/DataScience_Lessons/blob/main/TP_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfHy-10WIaAe"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "import pandas_datareader.data as web\n",
        "import datetime\n",
        "\n",
        "# Import libraries Keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUEvyHNcJo1j",
        "outputId": "c56b02e8-9cab-4f8c-fae6-e01f14f49844"
      },
      "source": [
        "start_day = 3\n",
        "start_month = 1\n",
        "start_year = 2017\n",
        "start_date = datetime.datetime(start_year,start_month,start_day)\n",
        "\n",
        "\n",
        "end_day = 26\n",
        "end_month = 2\n",
        "end_year = 2021\n",
        "end_date = datetime.datetime(end_year,end_month,end_day)\n",
        "\n",
        "print(start_date,end_date)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2017-01-03 00:00:00 2021-02-26 00:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz9dOXu0KzXh"
      },
      "source": [
        "# load data\n",
        "Sanofi_data = web.DataReader(\"SAN.PA\", 'yahoo', start_date, end_date)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUrC46qTLFOo"
      },
      "source": [
        "Sanofi_data  = Sanofi_data.rename_axis('Date').reset_index()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "-8zYGFCiL0af",
        "outputId": "2f7ff1db-ed17-40ac-d1ce-a2f8de2eca6f"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "px.line(Sanofi_data,x=\"Date\", y=\"Close\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"ccdeb483-9579-479b-94c0-b7309911b84f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"ccdeb483-9579-479b-94c0-b7309911b84f\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'ccdeb483-9579-479b-94c0-b7309911b84f',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Date=%{x}<br>Close=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scattergl\", \"x\": [\"2017-01-03T00:00:00\", \"2017-01-04T00:00:00\", \"2017-01-05T00:00:00\", \"2017-01-06T00:00:00\", \"2017-01-09T00:00:00\", \"2017-01-10T00:00:00\", \"2017-01-11T00:00:00\", \"2017-01-12T00:00:00\", \"2017-01-13T00:00:00\", \"2017-01-16T00:00:00\", \"2017-01-17T00:00:00\", \"2017-01-18T00:00:00\", \"2017-01-19T00:00:00\", \"2017-01-20T00:00:00\", \"2017-01-23T00:00:00\", \"2017-01-24T00:00:00\", \"2017-01-25T00:00:00\", \"2017-01-26T00:00:00\", \"2017-01-27T00:00:00\", \"2017-01-30T00:00:00\", \"2017-01-31T00:00:00\", \"2017-02-01T00:00:00\", \"2017-02-02T00:00:00\", \"2017-02-03T00:00:00\", \"2017-02-06T00:00:00\", \"2017-02-07T00:00:00\", \"2017-02-08T00:00:00\", \"2017-02-09T00:00:00\", \"2017-02-10T00:00:00\", \"2017-02-13T00:00:00\", \"2017-02-14T00:00:00\", \"2017-02-15T00:00:00\", \"2017-02-16T00:00:00\", \"2017-02-17T00:00:00\", \"2017-02-20T00:00:00\", \"2017-02-21T00:00:00\", \"2017-02-22T00:00:00\", \"2017-02-23T00:00:00\", \"2017-02-24T00:00:00\", \"2017-02-27T00:00:00\", \"2017-02-28T00:00:00\", \"2017-03-01T00:00:00\", \"2017-03-02T00:00:00\", \"2017-03-03T00:00:00\", \"2017-03-06T00:00:00\", \"2017-03-07T00:00:00\", \"2017-03-08T00:00:00\", \"2017-03-09T00:00:00\", \"2017-03-10T00:00:00\", \"2017-03-13T00:00:00\", \"2017-03-14T00:00:00\", \"2017-03-15T00:00:00\", \"2017-03-16T00:00:00\", \"2017-03-17T00:00:00\", \"2017-03-20T00:00:00\", \"2017-03-21T00:00:00\", \"2017-03-22T00:00:00\", \"2017-03-23T00:00:00\", \"2017-03-24T00:00:00\", \"2017-03-27T00:00:00\", \"2017-03-28T00:00:00\", \"2017-03-29T00:00:00\", \"2017-03-30T00:00:00\", \"2017-03-31T00:00:00\", \"2017-04-03T00:00:00\", \"2017-04-04T00:00:00\", \"2017-04-05T00:00:00\", \"2017-04-06T00:00:00\", \"2017-04-07T00:00:00\", \"2017-04-10T00:00:00\", \"2017-04-11T00:00:00\", \"2017-04-12T00:00:00\", \"2017-04-13T00:00:00\", \"2017-04-18T00:00:00\", \"2017-04-19T00:00:00\", \"2017-04-20T00:00:00\", \"2017-04-21T00:00:00\", \"2017-04-24T00:00:00\", \"2017-04-25T00:00:00\", \"2017-04-26T00:00:00\", \"2017-04-27T00:00:00\", \"2017-04-28T00:00:00\", \"2017-05-02T00:00:00\", \"2017-05-03T00:00:00\", \"2017-05-04T00:00:00\", \"2017-05-05T00:00:00\", \"2017-05-08T00:00:00\", \"2017-05-09T00:00:00\", \"2017-05-10T00:00:00\", \"2017-05-11T00:00:00\", \"2017-05-12T00:00:00\", \"2017-05-15T00:00:00\", \"2017-05-16T00:00:00\", \"2017-05-17T00:00:00\", \"2017-05-18T00:00:00\", \"2017-05-19T00:00:00\", \"2017-05-22T00:00:00\", \"2017-05-23T00:00:00\", \"2017-05-24T00:00:00\", \"2017-05-25T00:00:00\", \"2017-05-26T00:00:00\", \"2017-05-29T00:00:00\", \"2017-05-30T00:00:00\", \"2017-05-31T00:00:00\", \"2017-06-01T00:00:00\", \"2017-06-02T00:00:00\", \"2017-06-05T00:00:00\", \"2017-06-06T00:00:00\", \"2017-06-07T00:00:00\", \"2017-06-08T00:00:00\", \"2017-06-09T00:00:00\", \"2017-06-12T00:00:00\", \"2017-06-13T00:00:00\", \"2017-06-14T00:00:00\", \"2017-06-15T00:00:00\", \"2017-06-16T00:00:00\", \"2017-06-19T00:00:00\", \"2017-06-20T00:00:00\", \"2017-06-21T00:00:00\", \"2017-06-22T00:00:00\", \"2017-06-23T00:00:00\", \"2017-06-26T00:00:00\", \"2017-06-27T00:00:00\", \"2017-06-28T00:00:00\", \"2017-06-29T00:00:00\", \"2017-06-30T00:00:00\", \"2017-07-03T00:00:00\", \"2017-07-04T00:00:00\", \"2017-07-05T00:00:00\", \"2017-07-06T00:00:00\", \"2017-07-07T00:00:00\", \"2017-07-10T00:00:00\", \"2017-07-11T00:00:00\", \"2017-07-12T00:00:00\", \"2017-07-13T00:00:00\", \"2017-07-14T00:00:00\", \"2017-07-17T00:00:00\", \"2017-07-18T00:00:00\", \"2017-07-19T00:00:00\", \"2017-07-20T00:00:00\", \"2017-07-21T00:00:00\", \"2017-07-24T00:00:00\", \"2017-07-25T00:00:00\", \"2017-07-26T00:00:00\", \"2017-07-27T00:00:00\", \"2017-07-28T00:00:00\", \"2017-07-31T00:00:00\", \"2017-08-01T00:00:00\", \"2017-08-02T00:00:00\", \"2017-08-03T00:00:00\", \"2017-08-04T00:00:00\", \"2017-08-07T00:00:00\", \"2017-08-08T00:00:00\", \"2017-08-09T00:00:00\", \"2017-08-10T00:00:00\", \"2017-08-11T00:00:00\", \"2017-08-14T00:00:00\", \"2017-08-15T00:00:00\", \"2017-08-16T00:00:00\", \"2017-08-17T00:00:00\", \"2017-08-18T00:00:00\", \"2017-08-21T00:00:00\", \"2017-08-22T00:00:00\", \"2017-08-23T00:00:00\", \"2017-08-24T00:00:00\", \"2017-08-25T00:00:00\", \"2017-08-28T00:00:00\", \"2017-08-29T00:00:00\", \"2017-08-30T00:00:00\", \"2017-08-31T00:00:00\", \"2017-09-01T00:00:00\", \"2017-09-04T00:00:00\", \"2017-09-05T00:00:00\", \"2017-09-06T00:00:00\", \"2017-09-07T00:00:00\", \"2017-09-08T00:00:00\", \"2017-09-11T00:00:00\", \"2017-09-12T00:00:00\", \"2017-09-13T00:00:00\", \"2017-09-14T00:00:00\", \"2017-09-15T00:00:00\", \"2017-09-18T00:00:00\", \"2017-09-19T00:00:00\", \"2017-09-20T00:00:00\", \"2017-09-21T00:00:00\", \"2017-09-22T00:00:00\", \"2017-09-25T00:00:00\", \"2017-09-26T00:00:00\", \"2017-09-27T00:00:00\", \"2017-09-28T00:00:00\", \"2017-09-29T00:00:00\", \"2017-10-02T00:00:00\", \"2017-10-03T00:00:00\", \"2017-10-04T00:00:00\", \"2017-10-05T00:00:00\", \"2017-10-06T00:00:00\", \"2017-10-09T00:00:00\", \"2017-10-10T00:00:00\", \"2017-10-11T00:00:00\", \"2017-10-12T00:00:00\", \"2017-10-13T00:00:00\", \"2017-10-16T00:00:00\", \"2017-10-17T00:00:00\", \"2017-10-18T00:00:00\", \"2017-10-19T00:00:00\", \"2017-10-20T00:00:00\", \"2017-10-23T00:00:00\", \"2017-10-24T00:00:00\", \"2017-10-25T00:00:00\", \"2017-10-26T00:00:00\", \"2017-10-27T00:00:00\", \"2017-10-30T00:00:00\", \"2017-10-31T00:00:00\", \"2017-11-01T00:00:00\", \"2017-11-02T00:00:00\", \"2017-11-03T00:00:00\", \"2017-11-06T00:00:00\", \"2017-11-07T00:00:00\", \"2017-11-08T00:00:00\", \"2017-11-09T00:00:00\", \"2017-11-10T00:00:00\", \"2017-11-13T00:00:00\", \"2017-11-14T00:00:00\", \"2017-11-15T00:00:00\", \"2017-11-16T00:00:00\", \"2017-11-17T00:00:00\", \"2017-11-20T00:00:00\", \"2017-11-21T00:00:00\", \"2017-11-22T00:00:00\", \"2017-11-23T00:00:00\", \"2017-11-24T00:00:00\", \"2017-11-27T00:00:00\", \"2017-11-28T00:00:00\", \"2017-11-29T00:00:00\", \"2017-11-30T00:00:00\", \"2017-12-01T00:00:00\", \"2017-12-04T00:00:00\", \"2017-12-05T00:00:00\", \"2017-12-06T00:00:00\", \"2017-12-07T00:00:00\", \"2017-12-08T00:00:00\", \"2017-12-11T00:00:00\", \"2017-12-12T00:00:00\", \"2017-12-13T00:00:00\", \"2017-12-14T00:00:00\", \"2017-12-15T00:00:00\", \"2017-12-18T00:00:00\", \"2017-12-19T00:00:00\", \"2017-12-20T00:00:00\", \"2017-12-21T00:00:00\", \"2017-12-22T00:00:00\", \"2017-12-27T00:00:00\", \"2017-12-28T00:00:00\", \"2017-12-29T00:00:00\", \"2018-01-02T00:00:00\", \"2018-01-03T00:00:00\", \"2018-01-04T00:00:00\", \"2018-01-05T00:00:00\", \"2018-01-08T00:00:00\", \"2018-01-09T00:00:00\", \"2018-01-10T00:00:00\", \"2018-01-11T00:00:00\", \"2018-01-12T00:00:00\", \"2018-01-15T00:00:00\", \"2018-01-16T00:00:00\", \"2018-01-17T00:00:00\", \"2018-01-18T00:00:00\", \"2018-01-19T00:00:00\", \"2018-01-22T00:00:00\", \"2018-01-23T00:00:00\", \"2018-01-24T00:00:00\", \"2018-01-25T00:00:00\", \"2018-01-26T00:00:00\", \"2018-01-29T00:00:00\", \"2018-01-30T00:00:00\", \"2018-01-31T00:00:00\", \"2018-02-01T00:00:00\", \"2018-02-02T00:00:00\", \"2018-02-05T00:00:00\", \"2018-02-06T00:00:00\", \"2018-02-07T00:00:00\", \"2018-02-08T00:00:00\", \"2018-02-09T00:00:00\", \"2018-02-12T00:00:00\", \"2018-02-13T00:00:00\", \"2018-02-14T00:00:00\", \"2018-02-15T00:00:00\", \"2018-02-16T00:00:00\", \"2018-02-19T00:00:00\", \"2018-02-20T00:00:00\", \"2018-02-21T00:00:00\", \"2018-02-22T00:00:00\", \"2018-02-23T00:00:00\", \"2018-02-26T00:00:00\", \"2018-02-27T00:00:00\", \"2018-02-28T00:00:00\", \"2018-03-01T00:00:00\", \"2018-03-02T00:00:00\", \"2018-03-05T00:00:00\", \"2018-03-06T00:00:00\", \"2018-03-07T00:00:00\", \"2018-03-08T00:00:00\", \"2018-03-09T00:00:00\", \"2018-03-12T00:00:00\", \"2018-03-13T00:00:00\", \"2018-03-14T00:00:00\", \"2018-03-15T00:00:00\", \"2018-03-16T00:00:00\", \"2018-03-19T00:00:00\", \"2018-03-20T00:00:00\", \"2018-03-21T00:00:00\", \"2018-03-22T00:00:00\", \"2018-03-23T00:00:00\", \"2018-03-26T00:00:00\", \"2018-03-27T00:00:00\", \"2018-03-28T00:00:00\", \"2018-03-29T00:00:00\", \"2018-04-03T00:00:00\", \"2018-04-04T00:00:00\", \"2018-04-05T00:00:00\", \"2018-04-06T00:00:00\", \"2018-04-09T00:00:00\", \"2018-04-10T00:00:00\", \"2018-04-11T00:00:00\", \"2018-04-12T00:00:00\", \"2018-04-13T00:00:00\", \"2018-04-16T00:00:00\", \"2018-04-17T00:00:00\", \"2018-04-18T00:00:00\", \"2018-04-19T00:00:00\", \"2018-04-20T00:00:00\", \"2018-04-23T00:00:00\", \"2018-04-24T00:00:00\", \"2018-04-25T00:00:00\", \"2018-04-26T00:00:00\", \"2018-04-27T00:00:00\", \"2018-04-30T00:00:00\", \"2018-05-02T00:00:00\", \"2018-05-03T00:00:00\", \"2018-05-04T00:00:00\", \"2018-05-07T00:00:00\", \"2018-05-08T00:00:00\", \"2018-05-09T00:00:00\", \"2018-05-10T00:00:00\", \"2018-05-11T00:00:00\", \"2018-05-14T00:00:00\", \"2018-05-15T00:00:00\", \"2018-05-16T00:00:00\", \"2018-05-17T00:00:00\", \"2018-05-18T00:00:00\", \"2018-05-21T00:00:00\", \"2018-05-22T00:00:00\", \"2018-05-23T00:00:00\", \"2018-05-24T00:00:00\", \"2018-05-25T00:00:00\", \"2018-05-28T00:00:00\", \"2018-05-29T00:00:00\", \"2018-05-30T00:00:00\", \"2018-05-31T00:00:00\", \"2018-06-01T00:00:00\", \"2018-06-04T00:00:00\", \"2018-06-05T00:00:00\", \"2018-06-06T00:00:00\", \"2018-06-07T00:00:00\", \"2018-06-08T00:00:00\", \"2018-06-11T00:00:00\", \"2018-06-12T00:00:00\", \"2018-06-13T00:00:00\", \"2018-06-14T00:00:00\", \"2018-06-15T00:00:00\", \"2018-06-18T00:00:00\", \"2018-06-19T00:00:00\", \"2018-06-20T00:00:00\", \"2018-06-21T00:00:00\", \"2018-06-22T00:00:00\", \"2018-06-25T00:00:00\", \"2018-06-26T00:00:00\", \"2018-06-27T00:00:00\", \"2018-06-28T00:00:00\", \"2018-06-29T00:00:00\", \"2018-07-02T00:00:00\", \"2018-07-03T00:00:00\", \"2018-07-04T00:00:00\", \"2018-07-05T00:00:00\", \"2018-07-06T00:00:00\", \"2018-07-09T00:00:00\", \"2018-07-10T00:00:00\", \"2018-07-11T00:00:00\", \"2018-07-12T00:00:00\", \"2018-07-13T00:00:00\", \"2018-07-16T00:00:00\", \"2018-07-17T00:00:00\", \"2018-07-18T00:00:00\", \"2018-07-19T00:00:00\", \"2018-07-20T00:00:00\", \"2018-07-23T00:00:00\", \"2018-07-24T00:00:00\", \"2018-07-25T00:00:00\", \"2018-07-26T00:00:00\", \"2018-07-27T00:00:00\", \"2018-07-30T00:00:00\", \"2018-07-31T00:00:00\", \"2018-08-01T00:00:00\", \"2018-08-02T00:00:00\", \"2018-08-03T00:00:00\", \"2018-08-06T00:00:00\", \"2018-08-07T00:00:00\", \"2018-08-08T00:00:00\", \"2018-08-09T00:00:00\", \"2018-08-10T00:00:00\", \"2018-08-13T00:00:00\", \"2018-08-14T00:00:00\", \"2018-08-15T00:00:00\", \"2018-08-16T00:00:00\", \"2018-08-17T00:00:00\", \"2018-08-20T00:00:00\", \"2018-08-21T00:00:00\", \"2018-08-22T00:00:00\", \"2018-08-23T00:00:00\", \"2018-08-24T00:00:00\", \"2018-08-27T00:00:00\", \"2018-08-28T00:00:00\", \"2018-08-29T00:00:00\", \"2018-08-30T00:00:00\", \"2018-08-31T00:00:00\", \"2018-09-03T00:00:00\", \"2018-09-04T00:00:00\", \"2018-09-05T00:00:00\", \"2018-09-06T00:00:00\", \"2018-09-07T00:00:00\", \"2018-09-10T00:00:00\", \"2018-09-11T00:00:00\", \"2018-09-12T00:00:00\", \"2018-09-13T00:00:00\", \"2018-09-14T00:00:00\", \"2018-09-17T00:00:00\", \"2018-09-18T00:00:00\", \"2018-09-19T00:00:00\", \"2018-09-20T00:00:00\", \"2018-09-21T00:00:00\", \"2018-09-24T00:00:00\", \"2018-09-25T00:00:00\", \"2018-09-26T00:00:00\", \"2018-09-27T00:00:00\", \"2018-09-28T00:00:00\", \"2018-10-01T00:00:00\", \"2018-10-02T00:00:00\", \"2018-10-03T00:00:00\", \"2018-10-04T00:00:00\", \"2018-10-05T00:00:00\", \"2018-10-08T00:00:00\", \"2018-10-09T00:00:00\", \"2018-10-10T00:00:00\", \"2018-10-11T00:00:00\", \"2018-10-12T00:00:00\", \"2018-10-15T00:00:00\", \"2018-10-16T00:00:00\", \"2018-10-17T00:00:00\", \"2018-10-18T00:00:00\", \"2018-10-19T00:00:00\", \"2018-10-22T00:00:00\", \"2018-10-23T00:00:00\", \"2018-10-24T00:00:00\", \"2018-10-25T00:00:00\", \"2018-10-26T00:00:00\", \"2018-10-29T00:00:00\", \"2018-10-30T00:00:00\", \"2018-10-31T00:00:00\", \"2018-11-01T00:00:00\", \"2018-11-02T00:00:00\", \"2018-11-05T00:00:00\", \"2018-11-06T00:00:00\", \"2018-11-07T00:00:00\", \"2018-11-08T00:00:00\", \"2018-11-09T00:00:00\", \"2018-11-12T00:00:00\", \"2018-11-13T00:00:00\", \"2018-11-14T00:00:00\", \"2018-11-15T00:00:00\", \"2018-11-16T00:00:00\", \"2018-11-19T00:00:00\", \"2018-11-20T00:00:00\", \"2018-11-21T00:00:00\", \"2018-11-22T00:00:00\", \"2018-11-23T00:00:00\", \"2018-11-26T00:00:00\", \"2018-11-27T00:00:00\", \"2018-11-28T00:00:00\", \"2018-11-29T00:00:00\", \"2018-11-30T00:00:00\", \"2018-12-03T00:00:00\", \"2018-12-04T00:00:00\", \"2018-12-05T00:00:00\", \"2018-12-06T00:00:00\", \"2018-12-07T00:00:00\", \"2018-12-10T00:00:00\", \"2018-12-11T00:00:00\", \"2018-12-12T00:00:00\", \"2018-12-13T00:00:00\", \"2018-12-14T00:00:00\", \"2018-12-17T00:00:00\", \"2018-12-18T00:00:00\", \"2018-12-19T00:00:00\", \"2018-12-20T00:00:00\", \"2018-12-21T00:00:00\", \"2018-12-24T00:00:00\", \"2018-12-27T00:00:00\", \"2018-12-28T00:00:00\", \"2018-12-31T00:00:00\", \"2019-01-02T00:00:00\", \"2019-01-03T00:00:00\", \"2019-01-04T00:00:00\", \"2019-01-07T00:00:00\", \"2019-01-08T00:00:00\", \"2019-01-09T00:00:00\", \"2019-01-10T00:00:00\", \"2019-01-11T00:00:00\", \"2019-01-14T00:00:00\", \"2019-01-15T00:00:00\", \"2019-01-16T00:00:00\", \"2019-01-17T00:00:00\", \"2019-01-18T00:00:00\", \"2019-01-21T00:00:00\", \"2019-01-22T00:00:00\", \"2019-01-23T00:00:00\", \"2019-01-24T00:00:00\", \"2019-01-25T00:00:00\", \"2019-01-28T00:00:00\", \"2019-01-29T00:00:00\", \"2019-01-30T00:00:00\", \"2019-01-31T00:00:00\", \"2019-02-01T00:00:00\", \"2019-02-04T00:00:00\", \"2019-02-05T00:00:00\", \"2019-02-06T00:00:00\", \"2019-02-07T00:00:00\", \"2019-02-08T00:00:00\", \"2019-02-11T00:00:00\", \"2019-02-12T00:00:00\", \"2019-02-13T00:00:00\", \"2019-02-14T00:00:00\", \"2019-02-15T00:00:00\", \"2019-02-18T00:00:00\", \"2019-02-19T00:00:00\", \"2019-02-20T00:00:00\", \"2019-02-21T00:00:00\", \"2019-02-22T00:00:00\", \"2019-02-25T00:00:00\", \"2019-02-26T00:00:00\", \"2019-02-27T00:00:00\", \"2019-02-28T00:00:00\", \"2019-03-01T00:00:00\", \"2019-03-04T00:00:00\", \"2019-03-05T00:00:00\", \"2019-03-06T00:00:00\", \"2019-03-07T00:00:00\", \"2019-03-08T00:00:00\", \"2019-03-11T00:00:00\", \"2019-03-12T00:00:00\", \"2019-03-13T00:00:00\", \"2019-03-14T00:00:00\", \"2019-03-15T00:00:00\", \"2019-03-18T00:00:00\", \"2019-03-19T00:00:00\", \"2019-03-20T00:00:00\", \"2019-03-21T00:00:00\", \"2019-03-22T00:00:00\", \"2019-03-25T00:00:00\", \"2019-03-26T00:00:00\", \"2019-03-27T00:00:00\", \"2019-03-28T00:00:00\", \"2019-03-29T00:00:00\", \"2019-04-01T00:00:00\", \"2019-04-02T00:00:00\", \"2019-04-03T00:00:00\", \"2019-04-04T00:00:00\", \"2019-04-05T00:00:00\", \"2019-04-08T00:00:00\", \"2019-04-09T00:00:00\", \"2019-04-10T00:00:00\", \"2019-04-11T00:00:00\", \"2019-04-12T00:00:00\", \"2019-04-15T00:00:00\", \"2019-04-16T00:00:00\", \"2019-04-17T00:00:00\", \"2019-04-18T00:00:00\", \"2019-04-23T00:00:00\", \"2019-04-24T00:00:00\", \"2019-04-25T00:00:00\", \"2019-04-26T00:00:00\", \"2019-04-29T00:00:00\", \"2019-04-30T00:00:00\", \"2019-05-02T00:00:00\", \"2019-05-03T00:00:00\", \"2019-05-06T00:00:00\", \"2019-05-07T00:00:00\", \"2019-05-08T00:00:00\", \"2019-05-09T00:00:00\", \"2019-05-10T00:00:00\", \"2019-05-13T00:00:00\", \"2019-05-14T00:00:00\", \"2019-05-15T00:00:00\", \"2019-05-16T00:00:00\", \"2019-05-17T00:00:00\", \"2019-05-20T00:00:00\", \"2019-05-21T00:00:00\", \"2019-05-22T00:00:00\", \"2019-05-23T00:00:00\", \"2019-05-24T00:00:00\", \"2019-05-27T00:00:00\", \"2019-05-28T00:00:00\", \"2019-05-29T00:00:00\", \"2019-05-30T00:00:00\", \"2019-05-31T00:00:00\", \"2019-06-03T00:00:00\", \"2019-06-04T00:00:00\", \"2019-06-05T00:00:00\", \"2019-06-06T00:00:00\", \"2019-06-07T00:00:00\", \"2019-06-10T00:00:00\", \"2019-06-11T00:00:00\", \"2019-06-12T00:00:00\", \"2019-06-13T00:00:00\", \"2019-06-14T00:00:00\", \"2019-06-17T00:00:00\", \"2019-06-18T00:00:00\", \"2019-06-19T00:00:00\", \"2019-06-20T00:00:00\", \"2019-06-21T00:00:00\", \"2019-06-24T00:00:00\", \"2019-06-25T00:00:00\", \"2019-06-26T00:00:00\", \"2019-06-27T00:00:00\", \"2019-06-28T00:00:00\", \"2019-07-01T00:00:00\", \"2019-07-02T00:00:00\", \"2019-07-03T00:00:00\", \"2019-07-04T00:00:00\", \"2019-07-05T00:00:00\", \"2019-07-08T00:00:00\", \"2019-07-09T00:00:00\", \"2019-07-10T00:00:00\", \"2019-07-11T00:00:00\", \"2019-07-12T00:00:00\", \"2019-07-15T00:00:00\", \"2019-07-16T00:00:00\", \"2019-07-17T00:00:00\", \"2019-07-18T00:00:00\", \"2019-07-19T00:00:00\", \"2019-07-22T00:00:00\", \"2019-07-23T00:00:00\", \"2019-07-24T00:00:00\", \"2019-07-25T00:00:00\", \"2019-07-26T00:00:00\", \"2019-07-29T00:00:00\", \"2019-07-30T00:00:00\", \"2019-07-31T00:00:00\", \"2019-08-01T00:00:00\", \"2019-08-02T00:00:00\", \"2019-08-05T00:00:00\", \"2019-08-06T00:00:00\", \"2019-08-07T00:00:00\", \"2019-08-08T00:00:00\", \"2019-08-09T00:00:00\", \"2019-08-12T00:00:00\", \"2019-08-13T00:00:00\", \"2019-08-14T00:00:00\", \"2019-08-15T00:00:00\", \"2019-08-16T00:00:00\", \"2019-08-19T00:00:00\", \"2019-08-20T00:00:00\", \"2019-08-21T00:00:00\", \"2019-08-22T00:00:00\", \"2019-08-23T00:00:00\", \"2019-08-26T00:00:00\", \"2019-08-27T00:00:00\", \"2019-08-28T00:00:00\", \"2019-08-29T00:00:00\", \"2019-08-30T00:00:00\", \"2019-09-02T00:00:00\", \"2019-09-03T00:00:00\", \"2019-09-04T00:00:00\", \"2019-09-05T00:00:00\", \"2019-09-06T00:00:00\", \"2019-09-09T00:00:00\", \"2019-09-10T00:00:00\", \"2019-09-11T00:00:00\", \"2019-09-12T00:00:00\", \"2019-09-13T00:00:00\", \"2019-09-16T00:00:00\", \"2019-09-17T00:00:00\", \"2019-09-18T00:00:00\", \"2019-09-19T00:00:00\", \"2019-09-20T00:00:00\", \"2019-09-23T00:00:00\", \"2019-09-24T00:00:00\", \"2019-09-25T00:00:00\", \"2019-09-26T00:00:00\", \"2019-09-27T00:00:00\", \"2019-09-30T00:00:00\", \"2019-10-01T00:00:00\", \"2019-10-02T00:00:00\", \"2019-10-03T00:00:00\", \"2019-10-04T00:00:00\", \"2019-10-07T00:00:00\", \"2019-10-08T00:00:00\", \"2019-10-09T00:00:00\", \"2019-10-10T00:00:00\", \"2019-10-11T00:00:00\", \"2019-10-14T00:00:00\", \"2019-10-15T00:00:00\", \"2019-10-16T00:00:00\", \"2019-10-17T00:00:00\", \"2019-10-18T00:00:00\", \"2019-10-21T00:00:00\", \"2019-10-22T00:00:00\", \"2019-10-23T00:00:00\", \"2019-10-24T00:00:00\", \"2019-10-25T00:00:00\", \"2019-10-28T00:00:00\", \"2019-10-29T00:00:00\", \"2019-10-30T00:00:00\", \"2019-10-31T00:00:00\", \"2019-11-01T00:00:00\", \"2019-11-04T00:00:00\", \"2019-11-05T00:00:00\", \"2019-11-06T00:00:00\", \"2019-11-07T00:00:00\", \"2019-11-08T00:00:00\", \"2019-11-11T00:00:00\", \"2019-11-12T00:00:00\", \"2019-11-13T00:00:00\", \"2019-11-14T00:00:00\", \"2019-11-15T00:00:00\", \"2019-11-18T00:00:00\", \"2019-11-19T00:00:00\", \"2019-11-20T00:00:00\", \"2019-11-21T00:00:00\", \"2019-11-22T00:00:00\", \"2019-11-25T00:00:00\", \"2019-11-26T00:00:00\", \"2019-11-27T00:00:00\", \"2019-11-28T00:00:00\", \"2019-11-29T00:00:00\", \"2019-12-02T00:00:00\", \"2019-12-03T00:00:00\", \"2019-12-04T00:00:00\", \"2019-12-05T00:00:00\", \"2019-12-06T00:00:00\", \"2019-12-09T00:00:00\", \"2019-12-10T00:00:00\", \"2019-12-11T00:00:00\", \"2019-12-12T00:00:00\", \"2019-12-13T00:00:00\", \"2019-12-16T00:00:00\", \"2019-12-17T00:00:00\", \"2019-12-18T00:00:00\", \"2019-12-19T00:00:00\", \"2019-12-20T00:00:00\", \"2019-12-23T00:00:00\", \"2019-12-24T00:00:00\", \"2019-12-25T00:00:00\", \"2019-12-27T00:00:00\", \"2019-12-30T00:00:00\", \"2019-12-31T00:00:00\", \"2020-01-02T00:00:00\", \"2020-01-03T00:00:00\", \"2020-01-06T00:00:00\", \"2020-01-07T00:00:00\", \"2020-01-08T00:00:00\", \"2020-01-09T00:00:00\", \"2020-01-10T00:00:00\", \"2020-01-13T00:00:00\", \"2020-01-14T00:00:00\", \"2020-01-15T00:00:00\", \"2020-01-16T00:00:00\", \"2020-01-17T00:00:00\", \"2020-01-20T00:00:00\", \"2020-01-21T00:00:00\", \"2020-01-22T00:00:00\", \"2020-01-23T00:00:00\", \"2020-01-24T00:00:00\", \"2020-01-27T00:00:00\", \"2020-01-28T00:00:00\", \"2020-01-29T00:00:00\", \"2020-01-30T00:00:00\", \"2020-01-31T00:00:00\", \"2020-02-03T00:00:00\", \"2020-02-04T00:00:00\", \"2020-02-05T00:00:00\", \"2020-02-06T00:00:00\", \"2020-02-07T00:00:00\", \"2020-02-10T00:00:00\", \"2020-02-11T00:00:00\", \"2020-02-12T00:00:00\", \"2020-02-13T00:00:00\", \"2020-02-14T00:00:00\", \"2020-02-17T00:00:00\", \"2020-02-18T00:00:00\", \"2020-02-19T00:00:00\", \"2020-02-20T00:00:00\", \"2020-02-21T00:00:00\", \"2020-02-24T00:00:00\", \"2020-02-25T00:00:00\", \"2020-02-26T00:00:00\", \"2020-02-27T00:00:00\", \"2020-02-28T00:00:00\", \"2020-03-02T00:00:00\", \"2020-03-03T00:00:00\", \"2020-03-04T00:00:00\", \"2020-03-05T00:00:00\", \"2020-03-06T00:00:00\", \"2020-03-09T00:00:00\", \"2020-03-10T00:00:00\", \"2020-03-11T00:00:00\", \"2020-03-12T00:00:00\", \"2020-03-13T00:00:00\", \"2020-03-16T00:00:00\", \"2020-03-17T00:00:00\", \"2020-03-18T00:00:00\", \"2020-03-19T00:00:00\", \"2020-03-20T00:00:00\", \"2020-03-23T00:00:00\", \"2020-03-24T00:00:00\", \"2020-03-25T00:00:00\", \"2020-03-26T00:00:00\", \"2020-03-27T00:00:00\", \"2020-03-30T00:00:00\", \"2020-03-31T00:00:00\", \"2020-04-01T00:00:00\", \"2020-04-02T00:00:00\", \"2020-04-03T00:00:00\", \"2020-04-06T00:00:00\", \"2020-04-07T00:00:00\", \"2020-04-08T00:00:00\", \"2020-04-09T00:00:00\", \"2020-04-14T00:00:00\", \"2020-04-15T00:00:00\", \"2020-04-16T00:00:00\", \"2020-04-17T00:00:00\", \"2020-04-20T00:00:00\", \"2020-04-21T00:00:00\", \"2020-04-22T00:00:00\", \"2020-04-23T00:00:00\", \"2020-04-24T00:00:00\", \"2020-04-27T00:00:00\", \"2020-04-28T00:00:00\", \"2020-04-29T00:00:00\", \"2020-04-30T00:00:00\", \"2020-05-04T00:00:00\", \"2020-05-05T00:00:00\", \"2020-05-06T00:00:00\", \"2020-05-07T00:00:00\", \"2020-05-08T00:00:00\", \"2020-05-11T00:00:00\", \"2020-05-12T00:00:00\", \"2020-05-13T00:00:00\", \"2020-05-14T00:00:00\", \"2020-05-15T00:00:00\", \"2020-05-18T00:00:00\", \"2020-05-19T00:00:00\", \"2020-05-20T00:00:00\", \"2020-05-21T00:00:00\", \"2020-05-22T00:00:00\", \"2020-05-25T00:00:00\", \"2020-05-26T00:00:00\", \"2020-05-27T00:00:00\", \"2020-05-28T00:00:00\", \"2020-05-29T00:00:00\", \"2020-06-01T00:00:00\", \"2020-06-02T00:00:00\", \"2020-06-03T00:00:00\", \"2020-06-04T00:00:00\", \"2020-06-05T00:00:00\", \"2020-06-08T00:00:00\", \"2020-06-09T00:00:00\", \"2020-06-10T00:00:00\", \"2020-06-11T00:00:00\", \"2020-06-12T00:00:00\", \"2020-06-15T00:00:00\", \"2020-06-16T00:00:00\", \"2020-06-17T00:00:00\", \"2020-06-18T00:00:00\", \"2020-06-19T00:00:00\", \"2020-06-22T00:00:00\", \"2020-06-23T00:00:00\", \"2020-06-24T00:00:00\", \"2020-06-25T00:00:00\", \"2020-06-26T00:00:00\", \"2020-06-29T00:00:00\", \"2020-06-30T00:00:00\", \"2020-07-01T00:00:00\", \"2020-07-02T00:00:00\", \"2020-07-03T00:00:00\", \"2020-07-06T00:00:00\", \"2020-07-07T00:00:00\", \"2020-07-08T00:00:00\", \"2020-07-09T00:00:00\", \"2020-07-10T00:00:00\", \"2020-07-13T00:00:00\", \"2020-07-14T00:00:00\", \"2020-07-15T00:00:00\", \"2020-07-16T00:00:00\", \"2020-07-17T00:00:00\", \"2020-07-20T00:00:00\", \"2020-07-21T00:00:00\", \"2020-07-22T00:00:00\", \"2020-07-23T00:00:00\", \"2020-07-24T00:00:00\", \"2020-07-27T00:00:00\", \"2020-07-28T00:00:00\", \"2020-07-29T00:00:00\", \"2020-07-30T00:00:00\", \"2020-07-31T00:00:00\", \"2020-08-03T00:00:00\", \"2020-08-04T00:00:00\", \"2020-08-05T00:00:00\", \"2020-08-06T00:00:00\", \"2020-08-07T00:00:00\", \"2020-08-10T00:00:00\", \"2020-08-11T00:00:00\", \"2020-08-12T00:00:00\", \"2020-08-13T00:00:00\", \"2020-08-14T00:00:00\", \"2020-08-17T00:00:00\", \"2020-08-18T00:00:00\", \"2020-08-19T00:00:00\", \"2020-08-20T00:00:00\", \"2020-08-21T00:00:00\", \"2020-08-24T00:00:00\", \"2020-08-25T00:00:00\", \"2020-08-26T00:00:00\", \"2020-08-27T00:00:00\", \"2020-08-28T00:00:00\", \"2020-08-31T00:00:00\", \"2020-09-01T00:00:00\", \"2020-09-02T00:00:00\", \"2020-09-03T00:00:00\", \"2020-09-04T00:00:00\", \"2020-09-07T00:00:00\", \"2020-09-08T00:00:00\", \"2020-09-09T00:00:00\", \"2020-09-10T00:00:00\", \"2020-09-11T00:00:00\", \"2020-09-14T00:00:00\", \"2020-09-15T00:00:00\", \"2020-09-16T00:00:00\", \"2020-09-17T00:00:00\", \"2020-09-18T00:00:00\", \"2020-09-21T00:00:00\", \"2020-09-22T00:00:00\", \"2020-09-23T00:00:00\", \"2020-09-24T00:00:00\", \"2020-09-25T00:00:00\", \"2020-09-28T00:00:00\", \"2020-09-29T00:00:00\", \"2020-09-30T00:00:00\", \"2020-10-01T00:00:00\", \"2020-10-02T00:00:00\", \"2020-10-05T00:00:00\", \"2020-10-06T00:00:00\", \"2020-10-07T00:00:00\", \"2020-10-08T00:00:00\", \"2020-10-09T00:00:00\", \"2020-10-12T00:00:00\", \"2020-10-13T00:00:00\", \"2020-10-14T00:00:00\", \"2020-10-15T00:00:00\", \"2020-10-16T00:00:00\", \"2020-10-19T00:00:00\", \"2020-10-20T00:00:00\", \"2020-10-21T00:00:00\", \"2020-10-22T00:00:00\", \"2020-10-23T00:00:00\", \"2020-10-26T00:00:00\", \"2020-10-27T00:00:00\", \"2020-10-28T00:00:00\", \"2020-10-29T00:00:00\", \"2020-10-30T00:00:00\", \"2020-11-02T00:00:00\", \"2020-11-03T00:00:00\", \"2020-11-04T00:00:00\", \"2020-11-05T00:00:00\", \"2020-11-06T00:00:00\", \"2020-11-09T00:00:00\", \"2020-11-10T00:00:00\", \"2020-11-11T00:00:00\", \"2020-11-12T00:00:00\", \"2020-11-13T00:00:00\", \"2020-11-16T00:00:00\", \"2020-11-17T00:00:00\", \"2020-11-18T00:00:00\", \"2020-11-19T00:00:00\", \"2020-11-20T00:00:00\", \"2020-11-23T00:00:00\", \"2020-11-24T00:00:00\", \"2020-11-25T00:00:00\", \"2020-11-26T00:00:00\", \"2020-11-27T00:00:00\", \"2020-11-30T00:00:00\", \"2020-12-01T00:00:00\", \"2020-12-02T00:00:00\", \"2020-12-03T00:00:00\", \"2020-12-04T00:00:00\", \"2020-12-07T00:00:00\", \"2020-12-08T00:00:00\", \"2020-12-09T00:00:00\", \"2020-12-10T00:00:00\", \"2020-12-11T00:00:00\", \"2020-12-14T00:00:00\", \"2020-12-15T00:00:00\", \"2020-12-16T00:00:00\", \"2020-12-17T00:00:00\", \"2020-12-18T00:00:00\", \"2020-12-21T00:00:00\", \"2020-12-22T00:00:00\", \"2020-12-23T00:00:00\", \"2020-12-24T00:00:00\", \"2020-12-28T00:00:00\", \"2020-12-29T00:00:00\", \"2020-12-30T00:00:00\", \"2020-12-31T00:00:00\", \"2021-01-04T00:00:00\", \"2021-01-05T00:00:00\", \"2021-01-06T00:00:00\", \"2021-01-07T00:00:00\", \"2021-01-08T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-02-01T00:00:00\", \"2021-02-02T00:00:00\", \"2021-02-03T00:00:00\", \"2021-02-04T00:00:00\", \"2021-02-05T00:00:00\", \"2021-02-08T00:00:00\", \"2021-02-09T00:00:00\", \"2021-02-10T00:00:00\", \"2021-02-11T00:00:00\", \"2021-02-12T00:00:00\", \"2021-02-15T00:00:00\", \"2021-02-16T00:00:00\", \"2021-02-17T00:00:00\", \"2021-02-18T00:00:00\", \"2021-02-19T00:00:00\", \"2021-02-22T00:00:00\", \"2021-02-23T00:00:00\", \"2021-02-24T00:00:00\", \"2021-02-25T00:00:00\", \"2021-02-26T00:00:00\"], \"xaxis\": \"x\", \"y\": [78.30000305175781, 78.30000305175781, 78.2699966430664, 76.69000244140625, 77.5199966430664, 78.30999755859375, 77.31999969482422, 76.54000091552734, 78.06999969482422, 76.80999755859375, 76.12000274658203, 76.5, 75.7699966430664, 75.62000274658203, 74.83999633789062, 73.88999938964844, 74.23999786376953, 74.62000274658203, 74.48999786376953, 74.79000091552734, 74.48999786376953, 75.77999877929688, 74.9800033569336, 75.62000274658203, 75.63999938964844, 75.9000015258789, 76.6500015258789, 80.19000244140625, 80.1500015258789, 80.37999725341797, 80.5, 81.19999694824219, 81.62999725341797, 81.48999786376953, 80.55000305175781, 80.52999877929688, 80.2699966430664, 80.12999725341797, 80.58000183105469, 80.43000030517578, 81.33000183105469, 82.81999969482422, 82.63999938964844, 83.58999633789062, 82.44999694824219, 81.80000305175781, 82.1500015258789, 82.31999969482422, 82.23999786376953, 82.04000091552734, 82.20999908447266, 82.31999969482422, 83.0199966430664, 82.61000061035156, 82.73999786376953, 82.72000122070312, 82.7699966430664, 83.30000305175781, 82.87000274658203, 83.47000122070312, 83.94000244140625, 84.51000213623047, 84.23999786376953, 84.62000274658203, 84.4800033569336, 85.30000305175781, 85.43000030517578, 85.20999908447266, 84.6500015258789, 84.61000061035156, 84.80999755859375, 85.23999786376953, 85.33000183105469, 83.27999877929688, 82.7300033569336, 83.31999969482422, 82.36000061035156, 84.83999633789062, 85.08999633789062, 85.6500015258789, 85.97000122070312, 86.61000061035156, 87.58000183105469, 87.55000305175781, 89.4000015258789, 89.69000244140625, 89.37999725341797, 89.9800033569336, 90.69000244140625, 91.4000015258789, 92.75, 92.97000122070312, 90.75, 89.56999969482422, 88.3499984741211, 88.37999725341797, 87.75, 87.81999969482422, 87.5999984741211, 87.30999755859375, 87.73999786376953, 87.62000274658203, 87.55999755859375, 88.16999816894531, 87.87999725341797, 88.87000274658203, 88.69000244140625, 87.83000183105469, 86.08000183105469, 85.9800033569336, 86.13999938964844, 84.8499984741211, 85.33999633789062, 84.86000061035156, 85.4800033569336, 85.05999755859375, 86.69999694824219, 86.81999969482422, 86.55999755859375, 88.6500015258789, 87.87000274658203, 88.69999694824219, 87.62999725341797, 86.69999694824219, 84.54000091552734, 83.76000213623047, 84.19999694824219, 83.86000061035156, 84.22000122070312, 82.97000122070312, 83.66000366210938, 83.9000015258789, 83.36000061035156, 85.95999908447266, 85.22000122070312, 84.58000183105469, 83.80000305175781, 82.58999633789062, 82.23999786376953, 82.7699966430664, 81.5199966430664, 81.91000366210938, 82.66999816894531, 82.33000183105469, 82.20999908447266, 81.58999633789062, 80.72000122070312, 79.69000244140625, 80.0199966430664, 80.41999816894531, 81.61000061035156, 81.68000030517578, 82.18000030517578, 80.83999633789062, 80.80000305175781, 80.5999984741211, 81.16999816894531, 81.7699966430664, 82.58000183105469, 82.76000213623047, 82.26000213623047, 81.9000015258789, 82.23999786376953, 81.80000305175781, 82.23999786376953, 82.0999984741211, 81.83000183105469, 81.41999816894531, 80.75, 81.66000366210938, 82.70999908447266, 82.05000305175781, 81.94000244140625, 82.37999725341797, 81.93000030517578, 82.20999908447266, 81.4000015258789, 82.04000091552734, 81.69999694824219, 82.05999755859375, 81.37000274658203, 81.5199966430664, 82.25, 82.30000305175781, 83.87000274658203, 84.12000274658203, 84.63999938964844, 84.55999755859375, 84.54000091552734, 84.0199966430664, 84.01000213623047, 85.12000274658203, 84.63999938964844, 85.0, 85.68000030517578, 86.26000213623047, 86.05000305175781, 84.7300033569336, 84.41999816894531, 84.19999694824219, 83.5999984741211, 84.54000091552734, 83.88999938964844, 84.51000213623047, 84.26000213623047, 83.80999755859375, 84.38999938964844, 83.61000061035156, 81.41999816894531, 82.0, 82.27999877929688, 81.62000274658203, 81.29000091552734, 80.52999877929688, 79.54000091552734, 79.0199966430664, 79.5999984741211, 78.66999816894531, 78.86000061035156, 77.79000091552734, 77.43000030517578, 76.43000030517578, 75.61000061035156, 75.58000183105469, 75.97000122070312, 75.43000030517578, 75.75, 76.44000244140625, 76.70999908447266, 77.54000091552734, 77.44999694824219, 76.91000366210938, 77.3499984741211, 76.9800033569336, 76.5999984741211, 74.81999969482422, 75.0999984741211, 73.97000122070312, 73.25, 73.20999908447266, 73.18000030517578, 73.58000183105469, 75.02999877929688, 74.66000366210938, 73.7699966430664, 73.55000305175781, 74.19999694824219, 73.19999694824219, 72.94000244140625, 72.87999725341797, 72.55000305175781, 72.5199966430664, 72.1500015258789, 71.8499984741211, 71.76000213623047, 72.06999969482422, 73.0, 74.36000061035156, 74.3499984741211, 74.23999786376953, 73.33999633789062, 72.9000015258789, 73.66999816894531, 73.19999694824219, 73.4000015258789, 72.87000274658203, 72.37000274658203, 72.94999694824219, 70.83000183105469, 71.18000030517578, 72.0, 72.25, 73.4800033569336, 72.9000015258789, 72.30999755859375, 71.12000274658203, 70.36000061035156, 69.94999694824219, 69.0199966430664, 67.5199966430664, 66.70999908447266, 65.08999633789062, 63.38999938964844, 64.29000091552734, 63.56999969482422, 63.88999938964844, 63.5, 64.5, 64.30000305175781, 64.55000305175781, 64.69999694824219, 64.88999938964844, 65.05000305175781, 65.5199966430664, 65.58000183105469, 65.02999877929688, 64.6500015258789, 63.400001525878906, 64.5, 63.70000076293945, 64.08000183105469, 64.91000366210938, 65.58000183105469, 65.77999877929688, 65.36000061035156, 65.23999786376953, 66.2300033569336, 66.16999816894531, 66.16999816894531, 65.80000305175781, 65.02999877929688, 64.62999725341797, 63.709999084472656, 63.209999084472656, 63.91999816894531, 64.75, 65.33000183105469, 64.37000274658203, 64.44999694824219, 66.11000061035156, 66.0999984741211, 66.44999694824219, 67.0, 66.18000030517578, 66.30000305175781, 65.98999786376953, 66.05000305175781, 66.41000366210938, 65.80999755859375, 65.5999984741211, 65.27999877929688, 65.70999908447266, 65.41999816894531, 65.87000274658203, 66.30999755859375, 65.16000366210938, 65.79000091552734, 65.86000061035156, 65.19999694824219, 65.5, 65.83999633789062, 65.91000366210938, 66.26000213623047, 66.12999725341797, 63.7400016784668, 64.4000015258789, 64.63999938964844, 65.13999938964844, 66.12000274658203, 66.44000244140625, 66.18000030517578, 66.37000274658203, 66.2300033569336, 65.77999877929688, 65.77999877929688, 65.5199966430664, 65.77999877929688, 66.0999984741211, 65.62999725341797, 66.38999938964844, 66.4000015258789, 66.16999816894531, 65.55000305175781, 66.06999969482422, 66.43000030517578, 66.8499984741211, 66.19000244140625, 66.16999816894531, 67.33000183105469, 68.68000030517578, 68.25, 67.66999816894531, 68.30999755859375, 67.70999908447266, 69.01000213623047, 69.22000122070312, 69.16999816894531, 69.16999816894531, 68.47000122070312, 68.6500015258789, 68.80000305175781, 70.01000213623047, 70.94999694824219, 72.44000244140625, 72.5, 71.55999755859375, 71.62999725341797, 71.1500015258789, 72.2300033569336, 71.91000366210938, 71.66000366210938, 71.83999633789062, 72.51000213623047, 72.11000061035156, 72.36000061035156, 72.4800033569336, 72.83000183105469, 73.41000366210938, 74.05000305175781, 74.56999969482422, 73.94999694824219, 74.37000274658203, 75.5999984741211, 74.5, 74.0999984741211, 73.72000122070312, 73.95999908447266, 73.94999694824219, 73.16000366210938, 73.70999908447266, 73.48999786376953, 72.8499984741211, 72.16000366210938, 72.66000366210938, 73.30000305175781, 73.43000030517578, 74.37000274658203, 74.81999969482422, 74.72000122070312, 74.69999694824219, 74.62000274658203, 74.33999633789062, 74.94000244140625, 74.58000183105469, 73.98999786376953, 74.5, 73.1500015258789, 72.55000305175781, 72.2699966430664, 72.97000122070312, 73.48999786376953, 73.2699966430664, 74.61000061035156, 75.68000030517578, 75.62999725341797, 75.0999984741211, 74.9000015258789, 75.12000274658203, 74.66999816894531, 74.5, 73.86000061035156, 74.61000061035156, 75.48999786376953, 76.91000366210938, 76.55999755859375, 77.54000091552734, 76.93000030517578, 77.33999633789062, 76.3499984741211, 76.02999877929688, 75.52999877929688, 75.58999633789062, 76.63999938964844, 75.41999816894531, 73.77999877929688, 75.29000091552734, 76.41000366210938, 77.20999908447266, 77.80000305175781, 77.80000305175781, 77.30000305175781, 77.0199966430664, 76.12000274658203, 75.6500015258789, 74.45999908447266, 74.43000030517578, 75.56999969482422, 78.83999633789062, 79.01000213623047, 77.75, 78.63999938964844, 77.5999984741211, 78.68000030517578, 79.30999755859375, 80.19999694824219, 79.58999633789062, 80.20999908447266, 79.4800033569336, 78.2300033569336, 79.2300033569336, 78.55000305175781, 78.94000244140625, 78.48999786376953, 78.29000091552734, 79.4800033569336, 78.9000015258789, 78.54000091552734, 79.27999877929688, 78.87000274658203, 79.80999755859375, 78.22000122070312, 79.08999633789062, 78.06999969482422, 75.62000274658203, 76.55000305175781, 76.91000366210938, 78.08999633789062, 79.79000091552734, 78.5999984741211, 78.23999786376953, 77.41999816894531, 76.20999908447266, 76.80999755859375, 76.1500015258789, 75.68000030517578, 74.23999786376953, 73.76000213623047, 75.22000122070312, 75.66000366210938, 75.4000015258789, 74.66000366210938, 75.33999633789062, 73.83999633789062, 74.41999816894531, 74.12999725341797, 74.18000030517578, 74.12999725341797, 72.9000015258789, 74.19000244140625, 74.30999755859375, 73.70999908447266, 72.91999816894531, 73.08999633789062, 73.16000366210938, 72.98999786376953, 72.97000122070312, 73.27999877929688, 73.31999969482422, 74.61000061035156, 74.66000366210938, 75.81999969482422, 75.4000015258789, 76.05999755859375, 76.83999633789062, 76.04000091552734, 74.83000183105469, 75.26000213623047, 75.33999633789062, 75.52999877929688, 73.87999725341797, 73.38999938964844, 75.23999786376953, 75.38999938964844, 74.66999816894531, 74.19999694824219, 73.0999984741211, 72.56999969482422, 72.73999786376953, 72.73999786376953, 72.7300033569336, 73.5, 74.0, 75.02999877929688, 76.43000030517578, 76.58000183105469, 76.63999938964844, 76.77999877929688, 76.95999908447266, 77.4000015258789, 77.80000305175781, 78.3499984741211, 79.55000305175781, 79.22000122070312, 79.55000305175781, 79.4000015258789, 79.73999786376953, 78.30999755859375, 77.95999908447266, 78.33000183105469, 77.69000244140625, 78.70999908447266, 78.73999786376953, 78.8499984741211, 79.23999786376953, 78.70999908447266, 78.56999969482422, 78.48999786376953, 78.48999786376953, 78.25, 77.95999908447266, 77.13999938964844, 75.4000015258789, 75.0, 75.0999984741211, 73.05999755859375, 72.87000274658203, 74.16999816894531, 74.33999633789062, 73.62000274658203, 76.19999694824219, 77.48999786376953, 77.48999786376953, 77.02999877929688, 77.62000274658203, 76.70999908447266, 76.2300033569336, 76.33000183105469, 73.37999725341797, 72.72000122070312, 72.95999908447266, 73.4000015258789, 73.81999969482422, 75.04000091552734, 75.2300033569336, 74.33999633789062, 73.94999694824219, 74.9000015258789, 74.9000015258789, 75.16000366210938, 75.56999969482422, 74.23999786376953, 73.26000213623047, 73.19000244140625, 72.23999786376953, 73.75, 73.68000030517578, 73.70999908447266, 75.0199966430664, 78.31999969482422, 77.30000305175781, 76.0999984741211, 76.56999969482422, 75.9800033569336, 75.9800033569336, 75.47000122070312, 77.47000122070312, 77.87999725341797, 78.33000183105469, 77.68000030517578, 77.12000274658203, 77.05000305175781, 75.91999816894531, 75.68000030517578, 75.91000366210938, 76.83000183105469, 77.08999633789062, 78.23999786376953, 77.97000122070312, 77.80000305175781, 76.97000122070312, 77.48999786376953, 76.55000305175781, 75.0999984741211, 73.5, 73.79000091552734, 74.31999969482422, 74.25, 74.0, 74.56999969482422, 75.41000366210938, 75.86000061035156, 75.7300033569336, 75.4000015258789, 75.94999694824219, 77.0999984741211, 75.58000183105469, 75.45999908447266, 75.48999786376953, 74.22000122070312, 72.3499984741211, 72.23999786376953, 72.69000244140625, 74.61000061035156, 73.75, 73.81999969482422, 75.4000015258789, 75.43000030517578, 74.83000183105469, 75.98999786376953, 77.23999786376953, 77.05999755859375, 77.93000030517578, 77.0199966430664, 76.7300033569336, 76.94999694824219, 77.87000274658203, 77.4800033569336, 78.0199966430664, 78.12000274658203, 79.52999877929688, 81.05000305175781, 81.0999984741211, 81.19000244140625, 81.58999633789062, 79.26000213623047, 78.76000213623047, 79.16000366210938, 79.7699966430664, 79.52999877929688, 79.08999633789062, 80.0, 80.22000122070312, 81.41999816894531, 83.31999969482422, 83.69000244140625, 85.08999633789062, 84.87000274658203, 85.25, 85.05999755859375, 85.05999755859375, 83.55999755859375, 80.66999816894531, 81.19999694824219, 82.19999694824219, 82.30000305175781, 82.13999938964844, 81.8499984741211, 81.91000366210938, 82.05000305175781, 81.41000366210938, 82.44999694824219, 82.68000030517578, 83.72000122070312, 82.80000305175781, 82.80000305175781, 82.06999969482422, 81.97000122070312, 83.5199966430664, 83.4000015258789, 83.37999725341797, 84.16999816894531, 84.9800033569336, 82.62000274658203, 81.56999969482422, 82.69999694824219, 82.76000213623047, 83.27999877929688, 82.36000061035156, 83.0, 83.16999816894531, 83.83999633789062, 82.97000122070312, 81.68000030517578, 83.08000183105469, 84.41000366210938, 83.11000061035156, 82.87999725341797, 84.9000015258789, 84.0, 85.02999877929688, 84.5, 84.37999725341797, 84.45999908447266, 84.51000213623047, 82.5199966430664, 82.06999969482422, 83.88999938964844, 83.12999725341797, 83.55999755859375, 81.86000061035156, 86.66000366210938, 87.94999694824219, 88.51000213623047, 89.1500015258789, 90.5999984741211, 89.5999984741211, 90.0, 90.08999633789062, 90.86000061035156, 90.70999908447266, 90.62999725341797, 90.62999725341797, 90.83999633789062, 89.75, 89.62000274658203, 90.22000122070312, 90.77999877929688, 91.3499984741211, 91.02999877929688, 91.33999633789062, 92.0, 92.72000122070312, 92.06999969482422, 91.2699966430664, 91.72000122070312, 91.61000061035156, 92.19000244140625, 91.9000015258789, 91.36000061035156, 88.87000274658203, 89.20999908447266, 89.11000061035156, 86.69999694824219, 87.66999816894531, 88.66999816894531, 87.86000061035156, 86.94999694824219, 87.5999984741211, 88.55999755859375, 89.93000030517578, 93.6500015258789, 93.58000183105469, 93.47000122070312, 93.93000030517578, 92.93000030517578, 92.37999725341797, 92.23999786376953, 92.30999755859375, 93.70999908447266, 94.0, 93.5, 93.33000183105469, 91.56999969482422, 90.44000244140625, 90.9000015258789, 88.44000244140625, 83.93000030517578, 85.58999633789062, 86.08999633789062, 89.58000183105469, 89.47000122070312, 85.05999755859375, 79.93000030517578, 78.37000274658203, 79.62999725341797, 73.44000244140625, 73.41000366210938, 76.5999984741211, 78.44999694824219, 76.0999984741211, 75.87999725341797, 73.8499984741211, 72.05000305175781, 74.73999786376953, 76.80000305175781, 77.69999694824219, 77.0, 80.51000213623047, 80.13999938964844, 78.94000244140625, 79.4800033569336, 81.36000061035156, 84.83000183105469, 84.0, 82.0, 82.12999725341797, 82.6500015258789, 82.80999755859375, 84.83000183105469, 86.56999969482422, 88.4000015258789, 88.08999633789062, 88.16000366210938, 88.88999938964844, 90.94000244140625, 93.4000015258789, 92.19000244140625, 90.69999694824219, 89.19000244140625, 88.41999816894531, 90.69999694824219, 92.41999816894531, 90.75, 89.56999969482422, 88.91999816894531, 91.01000213623047, 89.48999786376953, 88.18000030517578, 87.22000122070312, 87.55999755859375, 86.83999633789062, 87.73999786376953, 86.98999786376953, 86.86000061035156, 87.66999816894531, 86.52999877929688, 86.18000030517578, 88.51000213623047, 87.52999877929688, 88.69000244140625, 88.81999969482422, 88.80000305175781, 88.8499984741211, 89.16000366210938, 89.68000030517578, 90.45999908447266, 90.69000244140625, 89.22000122070312, 89.0199966430664, 89.19000244140625, 91.06999969482422, 93.70999908447266, 92.31999969482422, 94.12000274658203, 93.02999877929688, 93.29000091552734, 91.05999755859375, 91.86000061035156, 91.0999984741211, 91.54000091552734, 90.6500015258789, 91.0999984741211, 91.95999908447266, 91.0, 92.48999786376953, 91.66000366210938, 90.55999755859375, 89.18000030517578, 88.91999816894531, 90.9800033569336, 91.48999786376953, 93.66999816894531, 92.91999816894531, 93.22000122070312, 94.29000091552734, 92.72000122070312, 91.51000213623047, 91.0999984741211, 88.80999755859375, 89.12000274658203, 89.5, 89.91999816894531, 88.55000305175781, 88.55000305175781, 90.26000213623047, 88.20999908447266, 87.4800033569336, 86.4000015258789, 87.37999725341797, 86.72000122070312, 87.62999725341797, 88.19999694824219, 86.98999786376953, 85.45999908447266, 86.51000213623047, 87.37999725341797, 87.63999938964844, 86.97000122070312, 86.33999633789062, 87.43000030517578, 87.66999816894531, 87.48999786376953, 86.1500015258789, 85.02999877929688, 84.87000274658203, 83.91000366210938, 85.18000030517578, 84.41000366210938, 83.56999969482422, 85.52999877929688, 85.69999694824219, 88.12000274658203, 86.69000244140625, 87.54000091552734, 87.05999755859375, 88.73999786376953, 88.25, 88.02999877929688, 88.44000244140625, 85.87999725341797, 84.76000213623047, 87.05999755859375, 87.13999938964844, 86.61000061035156, 87.31999969482422, 86.18000030517578, 85.33000183105469, 85.30000305175781, 86.08000183105469, 86.5199966430664, 84.87000274658203, 83.91000366210938, 85.27999877929688, 86.30999755859375, 86.5, 87.5199966430664, 87.08999633789062, 84.66999816894531, 86.02999877929688, 85.44000244140625, 84.62000274658203, 83.36000061035156, 82.73999786376953, 82.94000244140625, 82.81999969482422, 81.0, 79.04000091552734, 78.2300033569336, 77.37000274658203, 79.37999725341797, 81.66000366210938, 86.80999755859375, 85.66999816894531, 83.31999969482422, 84.93000030517578, 84.69000244140625, 87.2699966430664, 86.31999969482422, 85.80000305175781, 85.52999877929688, 84.81999969482422, 86.08999633789062, 85.63999938964844, 85.8499984741211, 84.08999633789062, 84.20999908447266, 84.22000122070312, 85.37000274658203, 85.20999908447266, 84.70999908447266, 84.0999984741211, 84.04000091552734, 83.02999877929688, 83.5999984741211, 82.81999969482422, 82.37999725341797, 81.5199966430664, 81.79000091552734, 78.5199966430664, 77.8499984741211, 76.2300033569336, 77.63999938964844, 78.0, 79.01000213623047, 77.19999694824219, 78.95999908447266, 78.30999755859375, 78.33999633789062, 78.66000366210938, 79.22000122070312, 78.86000061035156, 78.69999694824219, 79.0, 78.98999786376953, 78.51000213623047, 77.72000122070312, 78.79000091552734, 79.23999786376953, 79.19000244140625, 79.02999877929688, 80.97000122070312, 81.52999877929688, 81.62999725341797, 83.2300033569336, 82.3499984741211, 81.41999816894531, 81.45999908447266, 81.5, 81.06999969482422, 79.06999969482422, 79.08999633789062, 77.1500015258789, 78.20999908447266, 78.5999984741211, 77.7300033569336, 78.83000183105469, 80.01000213623047, 80.7699966430664, 80.58000183105469, 79.45999908447266, 77.80999755859375, 78.16000366210938, 78.54000091552734, 78.04000091552734, 78.77999877929688, 78.23999786376953, 77.01000213623047, 76.30000305175781, 76.62000274658203, 76.62999725341797, 75.6500015258789, 75.80000305175781], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Date\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Close\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ccdeb483-9579-479b-94c0-b7309911b84f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgZR4ksFTqnD",
        "outputId": "8f0ae20d-5ad6-4153-f2ee-e7b029c42dbc"
      },
      "source": [
        "def train_test_split(base,split_date):\n",
        "  train = base[base.Date <= split_date]\n",
        "  test = base[base.Date > split_date]\n",
        "  print(\"taille base d'entrainement:\",train.shape)\n",
        "  print(\"taille base de test:\",test.shape)\n",
        "  return train,test\n",
        "\n",
        "\n",
        "split_date = datetime.datetime(2021,1,29)\n",
        "df_train,df_test = train_test_split(Sanofi_data,split_date)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "taille base d'entrainement: (1042, 7)\n",
            "taille base de test: (20, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrmT0WaOQMJe"
      },
      "source": [
        "# conversion de la feature Close en values pour keras \n",
        "train = df_train.iloc[:, 4:5]\n",
        "training_set = df_train.iloc[:, 4:5].values\n",
        "\n",
        "# conversion de la feature Close en values pour keras \n",
        "test = df_test.iloc[:, 4:5]\n",
        "testing_set = df_test.iloc[:, 4:5].values"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "wkGX2zBhQcia",
        "outputId": "6f1d3462-28ff-439f-d71a-fe5f12f32f02"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78.300003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>78.300003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>78.269997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76.690002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>77.519997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Close\n",
              "0  78.300003\n",
              "1  78.300003\n",
              "2  78.269997\n",
              "3  76.690002\n",
              "4  77.519997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDGRvRSBQ32y"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "training_set_scaled = sc.fit_transform(training_set)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkhmO5wrQ0CU"
      },
      "source": [
        "# Creation du train set pour une prvision de la valeur de l'action au jour j \n",
        "# base sur les 60 jours prcdents (3 mois) \n",
        "X_train = []\n",
        "y_train = []\n",
        "# Dans X_train, les 60 jours prcdents le jour i\n",
        "# Dans y_train, le jour i\n",
        "# training_set_scaled tant une array, il faut ajouter le numro de colonne, soit 0 \n",
        "for i in range(60, len(training_set)):\n",
        "    X_train.append(training_set_scaled[i-60:i, 0])\n",
        "    y_train.append(training_set_scaled[i, 0])\n",
        "# transformation des listes X_train et y_train en array avec numpy    \n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuLz0GCxQ7vW",
        "outputId": "a55571ec-c2d4-4f1a-eacb-da219337ed3c"
      },
      "source": [
        "X_train.shape,y_train.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((982, 60), (982,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfhpL3NIRgdk",
        "outputId": "2ccf0748-082c-4ef5-a1c9-15deefeab580"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.48552133, 0.48552133, 0.48455588, ..., 0.64639649, 0.63256121,\n",
              "        0.65186618],\n",
              "       [0.48552133, 0.48455588, 0.43371952, ..., 0.63256121, 0.65186618,\n",
              "        0.66698849],\n",
              "       [0.48455588, 0.43371952, 0.4604246 , ..., 0.65186618, 0.66698849,\n",
              "        0.68532824],\n",
              "       ...,\n",
              "       [0.52027018, 0.59362946, 0.75933067, ..., 0.5871943 , 0.58848133,\n",
              "        0.57464606],\n",
              "       [0.59362946, 0.75933067, 0.72265115, ..., 0.58848133, 0.57464606,\n",
              "        0.510296  ],\n",
              "       [0.75933067, 0.72265115, 0.64703988, ..., 0.57464606, 0.510296  ,\n",
              "        0.51093939]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba5qaJ14lShr",
        "outputId": "bdbb8c2f-6807-426b-dc5a-25574722a83c"
      },
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))\n",
        "X_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(982, 60, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y0PYSoIHROG"
      },
      "source": [
        "## Partie 1 RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_Q9vhZeHIOI"
      },
      "source": [
        "# Initialisation RNN avec Sequential()\n",
        "regressor = Sequential()\n",
        "\n",
        "# premire couche LSTM et rgularisation Dropout\n",
        "# units = nbre de neurones de la couche\n",
        "# return_sequences=True car dans le rseau on empile plusieurs couches LSTM\n",
        "# dans input_shape, indication du train set avec le nbre de time steps (60) et le nbre de feature, ici 1 \n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_33bo31bk0tM"
      },
      "source": [
        "# deuxime couche LSTM layer et rgularisation Dropout identique couche prcdente\n",
        "# entres de cette couche = sortie de la couche prcdente : input_shape inutile \n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# troisime couche LSTM layer et rgularisation Dropout\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences = False))\n",
        "regressor.add(Dropout(0.2))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpI1OJASNxWm",
        "outputId": "b9dc3c1c-d442-485d-8f6b-b91189186692"
      },
      "source": [
        "# couche de sortie 1 seul neurone\n",
        "regressor.add(Dense(units = 1))\n",
        "\n",
        "# Compilation RNN\n",
        "# optimizer : cf doc Keras adam (ou RMSprop recommand pour les RNN)\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "regressor.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 60, 50)            10400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 50)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 60, 50)            20200     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 60, 50)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 60, 50)            20200     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 60, 50)            0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 71,051\n",
            "Trainable params: 71,051\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH7u5ZV8ik_F",
        "outputId": "d09a3829-b65f-4f0f-ed0d-ad23a2c7f871"
      },
      "source": [
        "regressor.fit(X_train, y_train, epochs = 50, batch_size = 32)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "31/31 [==============================] - 21s 99ms/step - loss: 0.0807\n",
            "Epoch 2/50\n",
            "31/31 [==============================] - 3s 98ms/step - loss: 0.0171\n",
            "Epoch 3/50\n",
            "31/31 [==============================] - 3s 96ms/step - loss: 0.0149\n",
            "Epoch 4/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0128\n",
            "Epoch 5/50\n",
            "31/31 [==============================] - 3s 98ms/step - loss: 0.0129\n",
            "Epoch 6/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0133\n",
            "Epoch 7/50\n",
            "31/31 [==============================] - 3s 99ms/step - loss: 0.0090\n",
            "Epoch 8/50\n",
            "31/31 [==============================] - 3s 99ms/step - loss: 0.0117\n",
            "Epoch 9/50\n",
            "31/31 [==============================] - 3s 98ms/step - loss: 0.0090\n",
            "Epoch 10/50\n",
            "31/31 [==============================] - 3s 98ms/step - loss: 0.0077\n",
            "Epoch 11/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0080\n",
            "Epoch 12/50\n",
            "31/31 [==============================] - 3s 98ms/step - loss: 0.0083\n",
            "Epoch 13/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0081\n",
            "Epoch 14/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0083\n",
            "Epoch 15/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0080\n",
            "Epoch 16/50\n",
            "31/31 [==============================] - 3s 96ms/step - loss: 0.0076\n",
            "Epoch 17/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0068\n",
            "Epoch 18/50\n",
            "31/31 [==============================] - 3s 96ms/step - loss: 0.0060\n",
            "Epoch 19/50\n",
            "31/31 [==============================] - 3s 96ms/step - loss: 0.0068\n",
            "Epoch 20/50\n",
            "31/31 [==============================] - 3s 95ms/step - loss: 0.0069\n",
            "Epoch 21/50\n",
            "31/31 [==============================] - 3s 96ms/step - loss: 0.0059\n",
            "Epoch 22/50\n",
            "31/31 [==============================] - 3s 98ms/step - loss: 0.0071\n",
            "Epoch 23/50\n",
            "31/31 [==============================] - 3s 98ms/step - loss: 0.0060\n",
            "Epoch 24/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0063\n",
            "Epoch 25/50\n",
            "31/31 [==============================] - 3s 96ms/step - loss: 0.0068\n",
            "Epoch 26/50\n",
            "31/31 [==============================] - 3s 95ms/step - loss: 0.0060\n",
            "Epoch 27/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0061\n",
            "Epoch 28/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0059\n",
            "Epoch 29/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0064\n",
            "Epoch 30/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0058\n",
            "Epoch 31/50\n",
            "31/31 [==============================] - 3s 96ms/step - loss: 0.0065\n",
            "Epoch 32/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0054\n",
            "Epoch 33/50\n",
            "31/31 [==============================] - 3s 98ms/step - loss: 0.0047\n",
            "Epoch 34/50\n",
            "31/31 [==============================] - 3s 98ms/step - loss: 0.0054\n",
            "Epoch 35/50\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.0054\n",
            "Epoch 36/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0053\n",
            "Epoch 37/50\n",
            "31/31 [==============================] - 3s 96ms/step - loss: 0.0053\n",
            "Epoch 38/50\n",
            "31/31 [==============================] - 3s 94ms/step - loss: 0.0046\n",
            "Epoch 39/50\n",
            "31/31 [==============================] - 3s 95ms/step - loss: 0.0056\n",
            "Epoch 40/50\n",
            "31/31 [==============================] - 3s 95ms/step - loss: 0.0052\n",
            "Epoch 41/50\n",
            "31/31 [==============================] - 3s 95ms/step - loss: 0.0045\n",
            "Epoch 42/50\n",
            "31/31 [==============================] - 3s 96ms/step - loss: 0.0048\n",
            "Epoch 43/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0048\n",
            "Epoch 44/50\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 0.0040\n",
            "Epoch 45/50\n",
            "31/31 [==============================] - 3s 96ms/step - loss: 0.0046\n",
            "Epoch 46/50\n",
            "31/31 [==============================] - 3s 95ms/step - loss: 0.0052\n",
            "Epoch 47/50\n",
            "31/31 [==============================] - 3s 96ms/step - loss: 0.0048\n",
            "Epoch 48/50\n",
            "31/31 [==============================] - 3s 95ms/step - loss: 0.0049\n",
            "Epoch 49/50\n",
            "31/31 [==============================] - 3s 94ms/step - loss: 0.0036\n",
            "Epoch 50/50\n",
            "31/31 [==============================] - 3s 95ms/step - loss: 0.0037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f91e81ae7d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXlEoTGzjK6z"
      },
      "source": [
        "real_stock_price = testing_set\n",
        "\n",
        "# prdictions du feature Close \n",
        "# concatnation des datasets train et test d'origine, au niveau des lignes avec axis = 0 (l'un au dessus de l'autre)\n",
        "dataset_total = pd.concat((df_train['Close'], df_test['Close']), axis = 0)\n",
        "# dans inputs on met les 60 jours prcdents le jour  prdire et ceci pour tous les jours du mois  prdire :\n",
        "# transformation en array pour keras\n",
        "inputs = dataset_total[len(dataset_total) - len(df_test) - 60:].values\n",
        "# redimensionnement ncessaire du dataset \n",
        "inputs = inputs.reshape(-1,1)\n",
        "# utilisation du meme objet sc utilise pour l'entrainement\n",
        "inputs = sc.transform(inputs)\n",
        "\n",
        "# alimentation du X_test avec les valeurs inputs correspondantes \n",
        "X_test = []\n",
        "# range de 60  80 puisque test set de 20 lignes\n",
        "for i in range(60, 80):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "# transformation en array    \n",
        "X_test = np.array(X_test)\n",
        "# redimensionnement en 3 dimensions avec reshape pour obtenir un X_test avec 20 lignes, 60 colonnes et 1 en troisime dimension\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "# prvisions avec fonction predict sur le modle regressor \n",
        "predicted_stock_price = regressor.predict(X_test)\n",
        "# prvisions sur l'chelle d'orignie avec transformation inverse\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDo4W-X3qtIf",
        "outputId": "65e8c4e9-31fb-48ee-c98e-db695a86ab64"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print(\"le R2 est:\",r2_score(real_stock_price, predicted_stock_price))\n",
        "print(\"le mse est:\",mean_squared_error(real_stock_price, predicted_stock_price))\n",
        "\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "le R2 est: 0.2762908580501685\n",
            "le mse est: 1.4671398516511545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "PpFIFmuFB5YD",
        "outputId": "dd737be4-a81b-4cf4-d70f-79a72532e627"
      },
      "source": [
        "result = pd.DataFrame([real_stock_price,predicted_stock_price], columns=[\"Valeur relle\", \"Valeur Predite\"])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-fefa94856910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_stock_price\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted_stock_price\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Valeur relle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Valeur Predite\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    521\u001b[0m                     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m                     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# by definition an array here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prep_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_prep_ndarray\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Must pass 2-d input. shape={values.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=(2, 20, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlfA1JPMCbrZ"
      },
      "source": [
        "df_predict = pd.DataFrame(predicted_stock_price, columns=[\"Prediction\"],index = df_test.index)\n",
        "df_true = pd.DataFrame(real_stock_price, columns=[\"Valeur\"],index = df_test.index)\n",
        "df_result = pd.concat([df_true,df_predict,df_test.Date],axis= 1)\n",
        "df_result[\"error\"] = df_result[\"Prediction\"] - df_result[\"Valeur\"]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "RbPbL48wrAcr",
        "outputId": "7de28725-a8ad-4add-9414-9591b27df5a6"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "# Visu rsultats vraies valeurs versus prvisions avec 50 poques\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df_result[\"Date\"],y=df_result[\"Prediction\"],name = \"Predictions\"))\n",
        "fig.add_trace(go.Scatter(x=df_result[\"Date\"],y=df_result[\"Valeur\"],name = \"valeurs\"))\n",
        "fig.show()\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"926c8677-7768-46d0-93f0-e0229f50870b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"926c8677-7768-46d0-93f0-e0229f50870b\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '926c8677-7768-46d0-93f0-e0229f50870b',\n",
              "                        [{\"name\": \"Predictions\", \"type\": \"scatter\", \"x\": [\"2021-02-01T00:00:00\", \"2021-02-02T00:00:00\", \"2021-02-03T00:00:00\", \"2021-02-04T00:00:00\", \"2021-02-05T00:00:00\", \"2021-02-08T00:00:00\", \"2021-02-09T00:00:00\", \"2021-02-10T00:00:00\", \"2021-02-11T00:00:00\", \"2021-02-12T00:00:00\", \"2021-02-15T00:00:00\", \"2021-02-16T00:00:00\", \"2021-02-17T00:00:00\", \"2021-02-18T00:00:00\", \"2021-02-19T00:00:00\", \"2021-02-22T00:00:00\", \"2021-02-23T00:00:00\", \"2021-02-24T00:00:00\", \"2021-02-25T00:00:00\", \"2021-02-26T00:00:00\"], \"y\": [79.15065002441406, 78.49305725097656, 78.26272583007812, 78.15703582763672, 78.28682708740234, 78.77984619140625, 79.54605865478516, 80.21183776855469, 80.3492660522461, 79.7907485961914, 79.08313751220703, 78.6085433959961, 78.31422424316406, 78.30682373046875, 78.36894226074219, 78.17488861083984, 77.70540618896484, 77.2443618774414, 76.92940521240234, 76.60270690917969]}, {\"name\": \"valeurs\", \"type\": \"scatter\", \"x\": [\"2021-02-01T00:00:00\", \"2021-02-02T00:00:00\", \"2021-02-03T00:00:00\", \"2021-02-04T00:00:00\", \"2021-02-05T00:00:00\", \"2021-02-08T00:00:00\", \"2021-02-09T00:00:00\", \"2021-02-10T00:00:00\", \"2021-02-11T00:00:00\", \"2021-02-12T00:00:00\", \"2021-02-15T00:00:00\", \"2021-02-16T00:00:00\", \"2021-02-17T00:00:00\", \"2021-02-18T00:00:00\", \"2021-02-19T00:00:00\", \"2021-02-22T00:00:00\", \"2021-02-23T00:00:00\", \"2021-02-24T00:00:00\", \"2021-02-25T00:00:00\", \"2021-02-26T00:00:00\"], \"y\": [78.20999908447266, 78.5999984741211, 77.7300033569336, 78.83000183105469, 80.01000213623047, 80.7699966430664, 80.58000183105469, 79.45999908447266, 77.80999755859375, 78.16000366210938, 78.54000091552734, 78.04000091552734, 78.77999877929688, 78.23999786376953, 77.01000213623047, 76.30000305175781, 76.62000274658203, 76.62999725341797, 75.6500015258789, 75.80000305175781]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('926c8677-7768-46d0-93f0-e0229f50870b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "KeniqOQwIcxt",
        "outputId": "7b2f09c7-a9ef-4204-8dbe-8e95a94329a4"
      },
      "source": [
        "px.scatter(df_result,x=\"Date\" , y=\"error\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"d755284f-a069-4db2-a39e-f8112ba984d6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"d755284f-a069-4db2-a39e-f8112ba984d6\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'd755284f-a069-4db2-a39e-f8112ba984d6',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Date=%{x}<br>error=%{y}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [\"2021-02-01T00:00:00\", \"2021-02-02T00:00:00\", \"2021-02-03T00:00:00\", \"2021-02-04T00:00:00\", \"2021-02-05T00:00:00\", \"2021-02-08T00:00:00\", \"2021-02-09T00:00:00\", \"2021-02-10T00:00:00\", \"2021-02-11T00:00:00\", \"2021-02-12T00:00:00\", \"2021-02-15T00:00:00\", \"2021-02-16T00:00:00\", \"2021-02-17T00:00:00\", \"2021-02-18T00:00:00\", \"2021-02-19T00:00:00\", \"2021-02-22T00:00:00\", \"2021-02-23T00:00:00\", \"2021-02-24T00:00:00\", \"2021-02-25T00:00:00\", \"2021-02-26T00:00:00\"], \"xaxis\": \"x\", \"y\": [0.9406509399414062, -0.10694122314453125, 0.5327224731445312, -0.6729660034179688, -1.723175048828125, -1.9901504516601562, -1.0339431762695312, 0.7518386840820312, 2.5392684936523438, 1.6307449340820312, 0.5431365966796875, 0.56854248046875, -0.4657745361328125, 0.06682586669921875, 1.3589401245117188, 1.8748855590820312, 1.0854034423828125, 0.6143646240234375, 1.2794036865234375, 0.802703857421875], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Date\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"error\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d755284f-a069-4db2-a39e-f8112ba984d6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIUObSO3Ypd1"
      },
      "source": [
        "## Partie2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTqOU1rRYpD_",
        "outputId": "74c14ede-46b4-4105-f2a2-97f2fab5b3a5"
      },
      "source": [
        "def build_LSTM():\n",
        "  regressor = Sequential() \n",
        "  regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "  regressor.add(Dropout(0.2))\n",
        "  regressor.add(LSTM(units = 100, return_sequences = True))\n",
        "  regressor.add(Dropout(0.2))\n",
        "  regressor.add(LSTM(units = 100, return_sequences = False))\n",
        "  regressor.add(Dropout(0.2))\n",
        "  regressor.add(Dense(units = 1))\n",
        "\n",
        "  regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "  regressor.summary()\n",
        "\n",
        "  return regressor\n",
        "\n",
        "\n",
        "regressor2 = build_LSTM()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 60, 100)           40800     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 60, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 201,701\n",
            "Trainable params: 201,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwJXWbGOaEQx",
        "outputId": "d79b180f-8d00-4490-b39c-cde4dec8de1b"
      },
      "source": [
        "regressor2.fit(X_train, y_train, epochs = 50, batch_size = 32)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "31/31 [==============================] - 8s 125ms/step - loss: 0.0811\n",
            "Epoch 2/50\n",
            "31/31 [==============================] - 4s 127ms/step - loss: 0.0095\n",
            "Epoch 3/50\n",
            "31/31 [==============================] - 4s 126ms/step - loss: 0.0083\n",
            "Epoch 4/50\n",
            "31/31 [==============================] - 4s 128ms/step - loss: 0.0094\n",
            "Epoch 5/50\n",
            "31/31 [==============================] - 4s 124ms/step - loss: 0.0086\n",
            "Epoch 6/50\n",
            "31/31 [==============================] - 4s 131ms/step - loss: 0.0071\n",
            "Epoch 7/50\n",
            "31/31 [==============================] - 4s 127ms/step - loss: 0.0065\n",
            "Epoch 8/50\n",
            "31/31 [==============================] - 4s 135ms/step - loss: 0.0066\n",
            "Epoch 9/50\n",
            "31/31 [==============================] - 4s 129ms/step - loss: 0.0060\n",
            "Epoch 10/50\n",
            "31/31 [==============================] - 4s 130ms/step - loss: 0.0057\n",
            "Epoch 11/50\n",
            "31/31 [==============================] - 4s 126ms/step - loss: 0.0061\n",
            "Epoch 12/50\n",
            "31/31 [==============================] - 4s 135ms/step - loss: 0.0053\n",
            "Epoch 13/50\n",
            "31/31 [==============================] - 4s 131ms/step - loss: 0.0056\n",
            "Epoch 14/50\n",
            "31/31 [==============================] - 4s 130ms/step - loss: 0.0050\n",
            "Epoch 15/50\n",
            "31/31 [==============================] - 4s 128ms/step - loss: 0.0044\n",
            "Epoch 16/50\n",
            "31/31 [==============================] - 4s 131ms/step - loss: 0.0047\n",
            "Epoch 17/50\n",
            "31/31 [==============================] - 4s 134ms/step - loss: 0.0045\n",
            "Epoch 18/50\n",
            "31/31 [==============================] - 4s 127ms/step - loss: 0.0049\n",
            "Epoch 19/50\n",
            "31/31 [==============================] - 4s 127ms/step - loss: 0.0044\n",
            "Epoch 20/50\n",
            "31/31 [==============================] - 4s 130ms/step - loss: 0.0042\n",
            "Epoch 21/50\n",
            "31/31 [==============================] - 4s 130ms/step - loss: 0.0048\n",
            "Epoch 22/50\n",
            "31/31 [==============================] - 4s 132ms/step - loss: 0.0038\n",
            "Epoch 23/50\n",
            "31/31 [==============================] - 4s 130ms/step - loss: 0.0039\n",
            "Epoch 24/50\n",
            "31/31 [==============================] - 4s 131ms/step - loss: 0.0047\n",
            "Epoch 25/50\n",
            "31/31 [==============================] - 4s 131ms/step - loss: 0.0041\n",
            "Epoch 26/50\n",
            "31/31 [==============================] - 4s 126ms/step - loss: 0.0050\n",
            "Epoch 27/50\n",
            "31/31 [==============================] - 4s 125ms/step - loss: 0.0041\n",
            "Epoch 28/50\n",
            "31/31 [==============================] - 4s 127ms/step - loss: 0.0038\n",
            "Epoch 29/50\n",
            "31/31 [==============================] - 4s 127ms/step - loss: 0.0035\n",
            "Epoch 30/50\n",
            "31/31 [==============================] - 4s 128ms/step - loss: 0.0041\n",
            "Epoch 31/50\n",
            "31/31 [==============================] - 4s 135ms/step - loss: 0.0037\n",
            "Epoch 32/50\n",
            "31/31 [==============================] - 4s 127ms/step - loss: 0.0034\n",
            "Epoch 33/50\n",
            "31/31 [==============================] - 4s 127ms/step - loss: 0.0036\n",
            "Epoch 34/50\n",
            "31/31 [==============================] - 4s 132ms/step - loss: 0.0032\n",
            "Epoch 35/50\n",
            "31/31 [==============================] - 4s 126ms/step - loss: 0.0034\n",
            "Epoch 36/50\n",
            "31/31 [==============================] - 4s 130ms/step - loss: 0.0042\n",
            "Epoch 37/50\n",
            "31/31 [==============================] - 4s 130ms/step - loss: 0.0038\n",
            "Epoch 38/50\n",
            "31/31 [==============================] - 4s 129ms/step - loss: 0.0032\n",
            "Epoch 39/50\n",
            "31/31 [==============================] - 4s 128ms/step - loss: 0.0034\n",
            "Epoch 40/50\n",
            "31/31 [==============================] - 4s 131ms/step - loss: 0.0031\n",
            "Epoch 41/50\n",
            "31/31 [==============================] - 4s 130ms/step - loss: 0.0033\n",
            "Epoch 42/50\n",
            "31/31 [==============================] - 4s 133ms/step - loss: 0.0035\n",
            "Epoch 43/50\n",
            "31/31 [==============================] - 4s 128ms/step - loss: 0.0029\n",
            "Epoch 44/50\n",
            "31/31 [==============================] - 4s 125ms/step - loss: 0.0028\n",
            "Epoch 45/50\n",
            "31/31 [==============================] - 4s 129ms/step - loss: 0.0028\n",
            "Epoch 46/50\n",
            "31/31 [==============================] - 4s 127ms/step - loss: 0.0026\n",
            "Epoch 47/50\n",
            "31/31 [==============================] - 4s 127ms/step - loss: 0.0027\n",
            "Epoch 48/50\n",
            "31/31 [==============================] - 4s 131ms/step - loss: 0.0031\n",
            "Epoch 49/50\n",
            "31/31 [==============================] - 4s 131ms/step - loss: 0.0029\n",
            "Epoch 50/50\n",
            "31/31 [==============================] - 4s 131ms/step - loss: 0.0028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f31e50ee7d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJta1LCOMY0e",
        "outputId": "db7cc208-1b09-427e-a80d-f72b47b23d62"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "LSTM_cv = KerasClassifier(build_fn = build_LSTM, batch_size = 10, epochs = 60)\n",
        "\n",
        "parameters = {'batch_size': [16, 32, 64],\n",
        "              'epochs': [10, 50, 100],}\n",
        "grid_search = GridSearchCV(estimator = LSTM_cv,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'neg_mean_squared_error',\n",
        "                           cv = 3)\n",
        "# entrainement \n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "# meilleurs rsultats \n",
        "best_parameters = grid_search.best_params_\n",
        "best_mse = grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_7 (LSTM)                (None, 60, 100)           40800     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 60, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 201,701\n",
            "Trainable params: 201,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "41/41 [==============================] - 9s 105ms/step - loss: 99153.8112\n",
            "Epoch 2/10\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 89507.2260\n",
            "Epoch 3/10\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 85492.9699\n",
            "Epoch 4/10\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 80532.9399\n",
            "Epoch 5/10\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 80714.2160\n",
            "Epoch 6/10\n",
            "41/41 [==============================] - 4s 104ms/step - loss: 78593.4395\n",
            "Epoch 7/10\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 75416.0257\n",
            "Epoch 8/10\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 78322.9561\n",
            "Epoch 9/10\n",
            "41/41 [==============================] - 4s 104ms/step - loss: 76246.4678\n",
            "Epoch 10/10\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 68808.0637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning:\n",
            "\n",
            "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_10 (LSTM)               (None, 60, 100)           40800     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 60, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 201,701\n",
            "Trainable params: 201,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "41/41 [==============================] - 9s 105ms/step - loss: 102692.3238\n",
            "Epoch 2/10\n",
            "41/41 [==============================] - 4s 110ms/step - loss: 99215.7513\n",
            "Epoch 3/10\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 95717.8884\n",
            "Epoch 4/10\n",
            "41/41 [==============================] - 5s 115ms/step - loss: 91930.7273\n",
            "Epoch 5/10\n",
            "41/41 [==============================] - 4s 104ms/step - loss: 91074.5346\n",
            "Epoch 6/10\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 93906.3471\n",
            "Epoch 7/10\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 87962.0869\n",
            "Epoch 8/10\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 85629.8455\n",
            "Epoch 9/10\n",
            "41/41 [==============================] - 4s 103ms/step - loss: 86281.6185\n",
            "Epoch 10/10\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 77271.7832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning:\n",
            "\n",
            "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_13 (LSTM)               (None, 60, 100)           40800     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 60, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 201,701\n",
            "Trainable params: 201,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "41/41 [==============================] - 9s 107ms/step - loss: 92746.9146\n",
            "Epoch 2/10\n",
            "41/41 [==============================] - 5s 113ms/step - loss: 84435.8763\n",
            "Epoch 3/10\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 80708.0167\n",
            "Epoch 4/10\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 78662.5218\n",
            "Epoch 5/10\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 80495.0733\n",
            "Epoch 6/10\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 80481.5275\n",
            "Epoch 7/10\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 71515.2438\n",
            "Epoch 8/10\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 77854.8441\n",
            "Epoch 9/10\n",
            "41/41 [==============================] - 5s 112ms/step - loss: 69834.0857\n",
            "Epoch 10/10\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 69631.5972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning:\n",
            "\n",
            "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_16 (LSTM)               (None, 60, 100)           40800     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               (None, 60, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 201,701\n",
            "Trainable params: 201,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "41/41 [==============================] - 10s 108ms/step - loss: 88964.5303\n",
            "Epoch 2/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 86604.8979\n",
            "Epoch 3/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 85881.6786\n",
            "Epoch 4/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 79466.6886\n",
            "Epoch 5/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 75477.6126\n",
            "Epoch 6/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 80789.3865\n",
            "Epoch 7/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 70134.3557\n",
            "Epoch 8/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 69571.2304\n",
            "Epoch 9/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 76157.3756\n",
            "Epoch 10/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 72045.5153\n",
            "Epoch 11/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 70426.2885\n",
            "Epoch 12/50\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 64168.9602\n",
            "Epoch 13/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 66298.2639\n",
            "Epoch 14/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 61812.1060\n",
            "Epoch 15/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 63230.2071\n",
            "Epoch 16/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 63370.5273\n",
            "Epoch 17/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 57510.0939\n",
            "Epoch 18/50\n",
            "41/41 [==============================] - 5s 113ms/step - loss: 57578.1672\n",
            "Epoch 19/50\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 55485.1928\n",
            "Epoch 20/50\n",
            "41/41 [==============================] - 5s 112ms/step - loss: 56669.9357\n",
            "Epoch 21/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 56889.5556\n",
            "Epoch 22/50\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 55142.9727\n",
            "Epoch 23/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 49301.4554\n",
            "Epoch 24/50\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 49531.1589\n",
            "Epoch 25/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 48818.4958\n",
            "Epoch 26/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 49208.6270\n",
            "Epoch 27/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 44897.5406\n",
            "Epoch 28/50\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 46561.2042\n",
            "Epoch 29/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 42954.1499\n",
            "Epoch 30/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 48639.9275\n",
            "Epoch 31/50\n",
            "41/41 [==============================] - 5s 114ms/step - loss: 41126.5314\n",
            "Epoch 32/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 43062.4978\n",
            "Epoch 33/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 42982.8228\n",
            "Epoch 34/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 42639.1348\n",
            "Epoch 35/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 43490.9774\n",
            "Epoch 36/50\n",
            "41/41 [==============================] - 5s 115ms/step - loss: 41448.2929\n",
            "Epoch 37/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 39268.5134\n",
            "Epoch 38/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 38041.6490\n",
            "Epoch 39/50\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 37111.4862\n",
            "Epoch 40/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 35724.2453\n",
            "Epoch 41/50\n",
            "41/41 [==============================] - 5s 112ms/step - loss: 38758.8270\n",
            "Epoch 42/50\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 37543.3746\n",
            "Epoch 43/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 37526.0625\n",
            "Epoch 44/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 37424.5331\n",
            "Epoch 45/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 37248.1162\n",
            "Epoch 46/50\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 34985.3911\n",
            "Epoch 47/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 36439.3376\n",
            "Epoch 48/50\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 35613.9383\n",
            "Epoch 49/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 31947.9842\n",
            "Epoch 50/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 33516.7600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning:\n",
            "\n",
            "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_19 (LSTM)               (None, 60, 100)           40800     \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 60, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 201,701\n",
            "Trainable params: 201,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "41/41 [==============================] - 9s 108ms/step - loss: 106686.2093\n",
            "Epoch 2/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 101746.7842\n",
            "Epoch 3/50\n",
            "41/41 [==============================] - 5s 117ms/step - loss: 96906.0482\n",
            "Epoch 4/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 95127.4284\n",
            "Epoch 5/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 83463.5791\n",
            "Epoch 6/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 92429.4347\n",
            "Epoch 7/50\n",
            "41/41 [==============================] - 5s 113ms/step - loss: 88086.8544\n",
            "Epoch 8/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 86752.8183\n",
            "Epoch 9/50\n",
            "41/41 [==============================] - 5s 114ms/step - loss: 85145.7253\n",
            "Epoch 10/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 85713.7379\n",
            "Epoch 11/50\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 80440.8209\n",
            "Epoch 12/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 81580.8434\n",
            "Epoch 13/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 76131.0402\n",
            "Epoch 14/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 76609.2656\n",
            "Epoch 15/50\n",
            "41/41 [==============================] - 5s 112ms/step - loss: 76325.1042\n",
            "Epoch 16/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 71808.4225\n",
            "Epoch 17/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 71525.2052\n",
            "Epoch 18/50\n",
            "41/41 [==============================] - 4s 104ms/step - loss: 66387.4240\n",
            "Epoch 19/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 67627.8405\n",
            "Epoch 20/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 70841.0906\n",
            "Epoch 21/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 58657.4339\n",
            "Epoch 22/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 64098.5445\n",
            "Epoch 23/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 63240.4209\n",
            "Epoch 24/50\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 61665.7417\n",
            "Epoch 25/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 57798.3933\n",
            "Epoch 26/50\n",
            "41/41 [==============================] - 4s 110ms/step - loss: 61382.7049\n",
            "Epoch 27/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 59074.6789\n",
            "Epoch 28/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 56784.4230\n",
            "Epoch 29/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 54954.9949\n",
            "Epoch 30/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 55663.4086\n",
            "Epoch 31/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 57191.3854\n",
            "Epoch 32/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 52756.1779\n",
            "Epoch 33/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 52243.6257\n",
            "Epoch 34/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 49854.5585\n",
            "Epoch 35/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 49101.6890\n",
            "Epoch 36/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 48667.9699\n",
            "Epoch 37/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 51138.8836\n",
            "Epoch 38/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 50269.8689\n",
            "Epoch 39/50\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 45883.7451\n",
            "Epoch 40/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 45140.1230\n",
            "Epoch 41/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 45679.9678\n",
            "Epoch 42/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 46605.7248\n",
            "Epoch 43/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 44620.5259\n",
            "Epoch 44/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 43796.1792\n",
            "Epoch 45/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 42113.4676\n",
            "Epoch 46/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 40136.0235\n",
            "Epoch 47/50\n",
            "41/41 [==============================] - 5s 112ms/step - loss: 42292.8703\n",
            "Epoch 48/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 38540.8701\n",
            "Epoch 49/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 38040.4999\n",
            "Epoch 50/50\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 37177.5493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning:\n",
            "\n",
            "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_22 (LSTM)               (None, 60, 100)           40800     \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_23 (LSTM)               (None, 60, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_24 (LSTM)               (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 201,701\n",
            "Trainable params: 201,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "41/41 [==============================] - 9s 106ms/step - loss: 86133.9144\n",
            "Epoch 2/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 85825.3279\n",
            "Epoch 3/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 85027.5004\n",
            "Epoch 4/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 86202.2708\n",
            "Epoch 5/50\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 83298.0562\n",
            "Epoch 6/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 78344.3222\n",
            "Epoch 7/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 74295.6149\n",
            "Epoch 8/50\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 74102.5276\n",
            "Epoch 9/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 73744.9420\n",
            "Epoch 10/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 72969.6107\n",
            "Epoch 11/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 67012.6995\n",
            "Epoch 12/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 64775.7925\n",
            "Epoch 13/50\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 67909.1270\n",
            "Epoch 14/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 62528.3610\n",
            "Epoch 15/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 60423.5981\n",
            "Epoch 16/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 61069.7541\n",
            "Epoch 17/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 55485.2705\n",
            "Epoch 18/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 59006.6544\n",
            "Epoch 19/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 55319.0476\n",
            "Epoch 20/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 55080.7405\n",
            "Epoch 21/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 50459.6456\n",
            "Epoch 22/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 54262.9870\n",
            "Epoch 23/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 50042.7589\n",
            "Epoch 24/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 52217.5556\n",
            "Epoch 25/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 50188.4452\n",
            "Epoch 26/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 45080.3034\n",
            "Epoch 27/50\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 45864.4538\n",
            "Epoch 28/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 48410.5031\n",
            "Epoch 29/50\n",
            "41/41 [==============================] - 5s 113ms/step - loss: 44718.0795\n",
            "Epoch 30/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 42602.2270\n",
            "Epoch 31/50\n",
            "41/41 [==============================] - 5s 112ms/step - loss: 44080.4350\n",
            "Epoch 32/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 42816.8055\n",
            "Epoch 33/50\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 44127.8397\n",
            "Epoch 34/50\n",
            "41/41 [==============================] - 5s 113ms/step - loss: 41190.0349\n",
            "Epoch 35/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 40294.0562\n",
            "Epoch 36/50\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 39601.2472\n",
            "Epoch 37/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 41060.4612\n",
            "Epoch 38/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 36949.3239\n",
            "Epoch 39/50\n",
            "41/41 [==============================] - 5s 112ms/step - loss: 38243.5698\n",
            "Epoch 40/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 37222.9548\n",
            "Epoch 41/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 39005.3892\n",
            "Epoch 42/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 35873.1698\n",
            "Epoch 43/50\n",
            "41/41 [==============================] - 5s 113ms/step - loss: 35372.0014\n",
            "Epoch 44/50\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 34155.7061\n",
            "Epoch 45/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 33806.2578\n",
            "Epoch 46/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 36363.4979\n",
            "Epoch 47/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 34100.6411\n",
            "Epoch 48/50\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 33126.6378\n",
            "Epoch 49/50\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 33770.9007\n",
            "Epoch 50/50\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 32081.5612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning:\n",
            "\n",
            "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_25 (LSTM)               (None, 60, 100)           40800     \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_26 (LSTM)               (None, 60, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_27 (LSTM)               (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 201,701\n",
            "Trainable params: 201,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "41/41 [==============================] - 9s 106ms/step - loss: 96157.9247\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 85288.8845\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 83558.0294\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 85800.7433\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 80105.2372\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 80176.6503\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 74938.0528\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 74942.0336\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 74161.2586\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 74078.9953\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 70315.5247\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 68408.9790\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 5s 109ms/step - loss: 67983.6971\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 59101.8594\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 65426.7147\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 63008.4814\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 62823.6469\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 60060.3813\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 59302.1524\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 57178.3758\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 57005.5974\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 53905.3768\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 53893.1149\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 50734.2263\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 52382.7768\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 50194.0854\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 5s 113ms/step - loss: 50890.5643\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 46932.2320\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 46314.1719\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 44771.7712\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 45681.8280\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 5s 114ms/step - loss: 42379.6241\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 43396.9733\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 42793.9175\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 38354.9681\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 5s 112ms/step - loss: 43831.4554\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 38960.2129\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 38761.1796\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 38259.2158\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 40733.4662\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 38093.7494\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 38760.3014\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 34831.3746\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 34213.3239\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 5s 113ms/step - loss: 37113.5003\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 31608.3455\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 33508.5362\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 36201.0619\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 34713.6257\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 32380.0408\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 32512.4743\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 5s 112ms/step - loss: 31645.3382\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 29245.6501\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 30242.5085\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 32159.7021\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 31190.1130\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 30232.6720\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 28730.5106\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 28222.3370\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 30149.7224\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 27977.2993\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 29774.0489\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 27473.0305\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 26706.2924\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 5s 113ms/step - loss: 29947.0708\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 27552.8181\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 4s 110ms/step - loss: 25388.1414\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 29874.6715\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 28139.8856\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 27555.2185\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 25808.5069\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 25161.3395\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 26274.4904\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 5s 115ms/step - loss: 27529.9818\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 25423.7943\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 27268.7578\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 24487.7595\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 25593.7735\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 25571.6918\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 26022.0659\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 25700.2736\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 5s 112ms/step - loss: 25561.9182\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 25589.5954\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 26091.2527\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 24198.8845\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 24636.7806\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 25276.8355\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 25731.1782\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 25545.2170\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 24441.6046\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 24715.0138\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 5s 112ms/step - loss: 24826.1650\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 5s 113ms/step - loss: 24730.6579\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 24743.4188\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 4s 110ms/step - loss: 25217.4362\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 24985.9895\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 24764.2952\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 26358.2281\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 24897.0241\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 5s 113ms/step - loss: 24966.5746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning:\n",
            "\n",
            "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_28 (LSTM)               (None, 60, 100)           40800     \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_29 (LSTM)               (None, 60, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_30 (LSTM)               (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 201,701\n",
            "Trainable params: 201,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "41/41 [==============================] - 9s 106ms/step - loss: 108151.6021\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 97131.9808\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 93965.4658\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 96092.0928\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 87005.0446\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 83234.9464\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 89914.0547\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 88693.1577\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 84639.4328\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 4s 110ms/step - loss: 72953.1528\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 78830.9625\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 77354.4265\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 77870.1408\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 72623.7693\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 71997.1732\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 69203.0674\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 73488.2254\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 5s 116ms/step - loss: 69665.1833\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 64592.7010\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 4s 110ms/step - loss: 67613.7439\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 67691.7007\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 64596.2168\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 4s 104ms/step - loss: 65435.2363\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 60364.3565\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 59174.5266\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 55484.1043\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 53947.1500\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 56290.5705\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 54770.2828\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 53078.1876\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 52264.7485\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 48841.1321\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 50388.6433\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 4s 110ms/step - loss: 49976.6126\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 50268.9719\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 47233.7609\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 48267.2594\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 5s 112ms/step - loss: 49283.4392\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 4s 110ms/step - loss: 43577.9230\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 46843.7813\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 40851.3654\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 42323.3070\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 42577.9781\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 44257.2617\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 41787.2585\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 42734.6612\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 37774.7553\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 38845.4965\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 42866.8517\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 40969.3065\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 37882.4133\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 36463.9721\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 5s 114ms/step - loss: 36838.5206\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 33458.8047\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 35611.9917\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 36251.7754\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 34503.6136\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 35568.5343\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 34685.4626\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 4s 104ms/step - loss: 35565.5047\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 33060.9995\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 31311.5079\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 4s 110ms/step - loss: 32443.7495\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 33801.6843\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 31055.3451\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 29930.0126\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 29387.1611\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 30978.8632\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 31249.5379\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 31720.5440\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 29358.7314\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 29382.7295\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 29713.9508\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 30215.2739\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 29131.9602\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 29360.2587\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 28122.8780\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 28586.8597\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 29973.5554\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 5s 110ms/step - loss: 27801.0335\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 29666.7703\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 28415.0975\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 5s 111ms/step - loss: 25794.4150\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 29070.9035\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 27332.2001\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 4s 103ms/step - loss: 28104.3025\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 4s 108ms/step - loss: 28002.6206\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 4s 109ms/step - loss: 29759.9155\n",
            "Epoch 89/100\n",
            "34/41 [=======================>......] - ETA: 0s - loss: 28431.3930"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "BKZSORRP_Ydf",
        "outputId": "97edaf85-5cfd-43f0-ae10-f0d2712862bb"
      },
      "source": [
        "best_parameters"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-dc31fafe3c30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'best_parameters' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33chcEwxZ--S"
      },
      "source": [
        "# prvisions avec fonction predict sur le modle regressor \n",
        "predicted_stock_price2 = regressor2.predict(X_test)\n",
        "# prvisions sur l'chelle d'orignie avec transformation inverse\n",
        "predicted_stock_price2 = sc.inverse_transform(predicted_stock_price2)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print(\"le R2 est:\",r2_score(real_stock_price, predicted_stock_price2))\n",
        "print(\"le mse est:\",mean_squared_error(real_stock_price, predicted_stock_price2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0wGbb8Sa_3N"
      },
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(real_stock_price, color = 'red', label = 'Valeur relle action')\n",
        "plt.plot(predicted_stock_price2, color = 'blue', label = 'Valeur prdite action')\n",
        "plt.title('Prediction valeur action RNN')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Prix action')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8y0c9M4E-nc"
      },
      "source": [
        "## Partie 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyzuHMa5M0PX"
      },
      "source": [
        "### Volume"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn07zkq0FChk"
      },
      "source": [
        "Sanofi_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWpX6xDnFKoy"
      },
      "source": [
        "fig = px.scatter(Sanofi_data, x=\"Volume\", y=\"Close\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSvy8BRwM79E"
      },
      "source": [
        "### Saisonalit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_ok58GDG9VG"
      },
      "source": [
        "Sanofi_data[\"year\"] = Sanofi_data[\"Date\"].dt.year\n",
        "Sanofi_data[\"month\"] = Sanofi_data[\"Date\"].dt.month\n",
        "Sanofi_data[\"week\"] = Sanofi_data[\"Date\"].dt.weekofyear\n",
        "Sanofi_data[\"day_week\"] = Sanofi_data[\"Date\"].dt.dayofweek\n",
        "Sanofi_data[\"day_month\"] = Sanofi_data[\"Date\"].dt.day\n",
        "Sanofi_data[\"day_year\"] = Sanofi_data[\"Date\"].dt.dayofyear\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLdCcolNLlAu"
      },
      "source": [
        "list_date = [\"year\",\"month\",\"week\",\"day_week\",\"day_month\",\"day_year\"]\n",
        "for date in list_date:\n",
        "  result = pd.DataFrame(Sanofi_data.groupby(date)[\"Close\"].agg(\"mean\")).reset_index()\n",
        "  fig = px.line(result, x=date, y=\"Close\")\n",
        "  fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8JjHDihc34L"
      },
      "source": [
        "**on trouve une saisonalit dans les jours du mois tout les 7 jours**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssyuKgkikV6g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}